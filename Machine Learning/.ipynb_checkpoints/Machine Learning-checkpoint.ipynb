{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('../node/data/sw_grade.csv', index_col = 'class_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['activity'] = df_raw['activity']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"등급\"] = df_raw[\"grade\"].apply(lambda x: 1 if x > 4.3 else 2 if x > 4.1 else 3 if x > 3.8\n",
    "                                    else 4 if x > 3.5\n",
    "                                    else 5 if x > 3.0 else 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_raw['..1']\n",
    "del df_raw['score']\n",
    "del df_raw['C_test']\n",
    "del df_raw['평점']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#n_convert = LabelEncoder()\n",
    "#df_y_converted = n_convert.fit_transform(df_raw['등급'])\n",
    "df_y_converted = df_raw['등급']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df_x = df_raw.iloc[:,0:5]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_x)\n",
    "df_x_scaled = DataFrame(scaler.transform(df_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>activity</th>\n",
       "      <th>Coding</th>\n",
       "      <th>Teamwork</th>\n",
       "      <th>Math</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1016.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.256209</td>\n",
       "      <td>3.076535</td>\n",
       "      <td>3.260074</td>\n",
       "      <td>3.407050</td>\n",
       "      <td>3.067150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.479880</td>\n",
       "      <td>0.618389</td>\n",
       "      <td>0.559622</td>\n",
       "      <td>0.725454</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.939302</td>\n",
       "      <td>2.220000</td>\n",
       "      <td>2.888889</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>3.271780</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.592728</td>\n",
       "      <td>3.330000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.446429</td>\n",
       "      <td>4.440000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             grade     activity       Coding     Teamwork         Math\n",
       "count  1016.000000  1016.000000  1016.000000  1016.000000  1016.000000\n",
       "mean      3.256209     3.076535     3.260074     3.407050     3.067150\n",
       "std       0.479880     0.618389     0.559622     0.725454     0.703704\n",
       "min       1.375000     1.110000     1.000000     1.000000     1.000000\n",
       "25%       2.939302     2.220000     2.888889     3.000000     2.583333\n",
       "50%       3.250000     3.330000     3.271780     3.500000     3.100000\n",
       "75%       3.592728     3.330000     3.666667     4.000000     3.600000\n",
       "max       4.446429     4.440000     4.500000     4.500000     4.500000"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_x_train, df_x_test, df_y_train, df_y_test = train_test_split(df_x_scaled, df_y_converted, test_size=0.4, random_state=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=1: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67         2\n",
      "           2       1.00      0.30      0.46        10\n",
      "           3       0.76      0.93      0.84        30\n",
      "           4       0.85      0.88      0.86        72\n",
      "           5       0.95      0.94      0.95       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.84      0.84      0.79       407\n",
      "weighted avg       0.93      0.92      0.92       407\n",
      "\n",
      "\n",
      "Classification Report for k=2: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      1.00      0.67         2\n",
      "           2       0.75      0.30      0.43        10\n",
      "           3       0.72      0.93      0.81        30\n",
      "           4       0.75      0.88      0.81        72\n",
      "           5       0.96      0.88      0.92       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       407\n",
      "   macro avg       0.78      0.83      0.77       407\n",
      "weighted avg       0.91      0.90      0.90       407\n",
      "\n",
      "\n",
      "Classification Report for k=3: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      1.00      0.80         2\n",
      "           2       0.80      0.40      0.53        10\n",
      "           3       0.74      0.93      0.82        30\n",
      "           4       0.87      0.86      0.87        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       407\n",
      "   macro avg       0.84      0.85      0.83       407\n",
      "weighted avg       0.93      0.93      0.93       407\n",
      "\n",
      "\n",
      "Classification Report for k=4: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      1.00      0.80         2\n",
      "           2       0.80      0.40      0.53        10\n",
      "           3       0.74      0.93      0.82        30\n",
      "           4       0.83      0.88      0.85        72\n",
      "           5       0.96      0.93      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.83      0.85      0.82       407\n",
      "weighted avg       0.93      0.92      0.92       407\n",
      "\n",
      "\n",
      "Classification Report for k=5: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       0.83      0.50      0.62        10\n",
      "           3       0.74      0.87      0.80        30\n",
      "           4       0.83      0.83      0.83        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.89      0.85      0.86       407\n",
      "weighted avg       0.92      0.92      0.92       407\n",
      "\n",
      "\n",
      "Classification Report for k=6: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.50      0.50         2\n",
      "           2       0.57      0.40      0.47        10\n",
      "           3       0.69      0.90      0.78        30\n",
      "           4       0.82      0.83      0.83        72\n",
      "           5       0.95      0.93      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.76      0.76      0.75       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=7: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       0.71      0.50      0.59        10\n",
      "           3       0.73      0.80      0.76        30\n",
      "           4       0.82      0.81      0.81        72\n",
      "           5       0.93      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.86      0.76      0.79       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=8: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       0.62      0.50      0.56        10\n",
      "           3       0.66      0.83      0.74        30\n",
      "           4       0.81      0.83      0.82        72\n",
      "           5       0.96      0.94      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.84      0.76      0.79       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=9: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       0.57      0.40      0.47        10\n",
      "           3       0.70      0.77      0.73        30\n",
      "           4       0.86      0.86      0.86        72\n",
      "           5       0.95      0.97      0.96       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.85      0.75      0.78       407\n",
      "weighted avg       0.92      0.92      0.92       407\n",
      "\n",
      "\n",
      "Classification Report for k=10: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       0.62      0.50      0.56        10\n",
      "           3       0.70      0.77      0.73        30\n",
      "           4       0.82      0.88      0.85        72\n",
      "           5       0.96      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.85      0.76      0.79       407\n",
      "weighted avg       0.92      0.92      0.92       407\n",
      "\n",
      "\n",
      "Classification Report for k=11: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       0.50      0.30      0.37        10\n",
      "           3       0.65      0.73      0.69        30\n",
      "           4       0.84      0.85      0.84        72\n",
      "           5       0.95      0.97      0.96       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.82      0.72      0.75       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=12: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       0.57      0.40      0.47        10\n",
      "           3       0.66      0.77      0.71        30\n",
      "           4       0.81      0.86      0.83        72\n",
      "           5       0.96      0.94      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.83      0.74      0.77       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=13: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.50      0.40      0.44        10\n",
      "           3       0.71      0.73      0.72        30\n",
      "           4       0.82      0.88      0.85        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.66      0.66      0.66       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=14: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.60      0.60      0.60        10\n",
      "           3       0.79      0.73      0.76        30\n",
      "           4       0.79      0.90      0.84        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.69      0.69      0.69       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=15: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.56      0.50      0.53        10\n",
      "           3       0.78      0.70      0.74        30\n",
      "           4       0.82      0.92      0.87        72\n",
      "           5       0.95      0.96      0.96       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.69      0.68      0.68       407\n",
      "weighted avg       0.92      0.92      0.92       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=16: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.55      0.60      0.57        10\n",
      "           3       0.74      0.67      0.70        30\n",
      "           4       0.80      0.89      0.84        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.67      0.68      0.68       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=17: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.55      0.60      0.57        10\n",
      "           3       0.74      0.67      0.70        30\n",
      "           4       0.81      0.89      0.85        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.67      0.68      0.68       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=18: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.55      0.60      0.57        10\n",
      "           3       0.75      0.70      0.72        30\n",
      "           4       0.82      0.89      0.85        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.68      0.69      0.68       407\n",
      "weighted avg       0.91      0.92      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=19: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.55      0.60      0.57        10\n",
      "           3       0.74      0.67      0.70        30\n",
      "           4       0.81      0.88      0.84        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.67      0.68      0.68       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=20: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.64      0.70      0.67        10\n",
      "           3       0.79      0.77      0.78        30\n",
      "           4       0.82      0.88      0.85        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.70      0.71      0.70       407\n",
      "weighted avg       0.92      0.92      0.92       407\n",
      "\n",
      "\n",
      "Classification Report for k=21: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.64      0.70      0.67        10\n",
      "           3       0.79      0.77      0.78        30\n",
      "           4       0.82      0.89      0.85        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.70      0.71      0.71       407\n",
      "weighted avg       0.92      0.92      0.92       407\n",
      "\n",
      "\n",
      "Classification Report for k=22: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.64      0.70      0.67        10\n",
      "           3       0.79      0.77      0.78        30\n",
      "           4       0.83      0.88      0.85        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.70      0.71      0.71       407\n",
      "weighted avg       0.92      0.92      0.92       407\n",
      "\n",
      "\n",
      "Classification Report for k=23: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.60      0.60      0.60        10\n",
      "           3       0.79      0.77      0.78        30\n",
      "           4       0.84      0.90      0.87        72\n",
      "           5       0.95      0.96      0.96       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       407\n",
      "   macro avg       0.70      0.70      0.70       407\n",
      "weighted avg       0.92      0.93      0.92       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=24: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.62      0.80      0.70        10\n",
      "           3       0.81      0.73      0.77        30\n",
      "           4       0.83      0.88      0.85        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.70      0.72      0.71       407\n",
      "weighted avg       0.92      0.92      0.92       407\n",
      "\n",
      "\n",
      "Classification Report for k=25: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.64      0.70      0.67        10\n",
      "           3       0.81      0.70      0.75        30\n",
      "           4       0.83      0.90      0.87        72\n",
      "           5       0.95      0.97      0.96       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       407\n",
      "   macro avg       0.71      0.71      0.71       407\n",
      "weighted avg       0.92      0.93      0.92       407\n",
      "\n",
      "\n",
      "Classification Report for k=26: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.67      0.80      0.73        10\n",
      "           3       0.82      0.77      0.79        30\n",
      "           4       0.84      0.88      0.86        72\n",
      "           5       0.95      0.96      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       407\n",
      "   macro avg       0.71      0.73      0.72       407\n",
      "weighted avg       0.92      0.93      0.92       407\n",
      "\n",
      "\n",
      "Classification Report for k=27: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.73      0.80      0.76        10\n",
      "           3       0.81      0.73      0.77        30\n",
      "           4       0.82      0.89      0.85        72\n",
      "           5       0.95      0.96      0.96       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       407\n",
      "   macro avg       0.72      0.73      0.72       407\n",
      "weighted avg       0.92      0.93      0.92       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=28: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.73      0.80      0.76        10\n",
      "           3       0.81      0.73      0.77        30\n",
      "           4       0.80      0.89      0.84        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.72      0.72      0.72       407\n",
      "weighted avg       0.92      0.92      0.92       407\n",
      "\n",
      "\n",
      "Classification Report for k=29: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.56      0.50      0.53        10\n",
      "           3       0.74      0.67      0.70        30\n",
      "           4       0.81      0.89      0.85        72\n",
      "           5       0.95      0.96      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.68      0.67      0.67       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=30: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.71      0.50      0.59        10\n",
      "           3       0.76      0.73      0.75        30\n",
      "           4       0.80      0.89      0.84        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.70      0.68      0.69       407\n",
      "weighted avg       0.91      0.92      0.91       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=31: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.71      0.50      0.59        10\n",
      "           3       0.74      0.67      0.70        30\n",
      "           4       0.79      0.88      0.83        72\n",
      "           5       0.94      0.96      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.70      0.66      0.68       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=32: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.71      0.50      0.59        10\n",
      "           3       0.77      0.77      0.77        30\n",
      "           4       0.81      0.88      0.84        72\n",
      "           5       0.94      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.71      0.68      0.69       407\n",
      "weighted avg       0.91      0.92      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=33: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.71      0.50      0.59        10\n",
      "           3       0.78      0.70      0.74        30\n",
      "           4       0.79      0.89      0.84        72\n",
      "           5       0.94      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.70      0.67      0.68       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=34: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.80      0.40      0.53        10\n",
      "           3       0.72      0.77      0.74        30\n",
      "           4       0.81      0.88      0.84        72\n",
      "           5       0.94      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.71      0.66      0.68       407\n",
      "weighted avg       0.91      0.91      0.91       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=35: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.67      0.40      0.50        10\n",
      "           3       0.77      0.67      0.71        30\n",
      "           4       0.81      0.90      0.86        72\n",
      "           5       0.94      0.97      0.96       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.70      0.65      0.67       407\n",
      "weighted avg       0.91      0.92      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=36: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.60      0.30      0.40        10\n",
      "           3       0.76      0.73      0.75        30\n",
      "           4       0.81      0.90      0.86        72\n",
      "           5       0.94      0.96      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       407\n",
      "   macro avg       0.69      0.65      0.66       407\n",
      "weighted avg       0.91      0.92      0.91       407\n",
      "\n",
      "\n",
      "Classification Report for k=37: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.50      0.20      0.29        10\n",
      "           3       0.71      0.67      0.69        30\n",
      "           4       0.78      0.90      0.84        72\n",
      "           5       0.94      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       407\n",
      "   macro avg       0.66      0.62      0.62       407\n",
      "weighted avg       0.90      0.91      0.90       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=38: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.62      0.67      0.65        30\n",
      "           4       0.79      0.92      0.85        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       407\n",
      "   macro avg       0.56      0.59      0.57       407\n",
      "weighted avg       0.88      0.90      0.89       407\n",
      "\n",
      "\n",
      "Classification Report for k=39: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.60      0.60      0.60        30\n",
      "           4       0.77      0.92      0.84        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       407\n",
      "   macro avg       0.55      0.57      0.56       407\n",
      "weighted avg       0.88      0.90      0.89       407\n",
      "\n",
      "\n",
      "Classification Report for k=40: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.61      0.63      0.62        30\n",
      "           4       0.77      0.92      0.84        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       407\n",
      "   macro avg       0.55      0.58      0.57       407\n",
      "weighted avg       0.88      0.90      0.89       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=41: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.57      0.53      0.55        30\n",
      "           4       0.75      0.90      0.82        72\n",
      "           5       0.94      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       407\n",
      "   macro avg       0.54      0.56      0.55       407\n",
      "weighted avg       0.87      0.89      0.88       407\n",
      "\n",
      "\n",
      "Classification Report for k=42: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.57      0.53      0.55        30\n",
      "           4       0.74      0.92      0.82        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       407\n",
      "   macro avg       0.54      0.56      0.55       407\n",
      "weighted avg       0.87      0.89      0.88       407\n",
      "\n",
      "\n",
      "Classification Report for k=43: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.54      0.47      0.50        30\n",
      "           4       0.73      0.92      0.81        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       407\n",
      "   macro avg       0.54      0.55      0.54       407\n",
      "weighted avg       0.87      0.89      0.88       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=44: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.54      0.47      0.50        30\n",
      "           4       0.72      0.92      0.80        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       407\n",
      "   macro avg       0.53      0.55      0.54       407\n",
      "weighted avg       0.86      0.88      0.87       407\n",
      "\n",
      "\n",
      "Classification Report for k=45: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.52      0.43      0.47        30\n",
      "           4       0.71      0.90      0.80        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       407\n",
      "   macro avg       0.53      0.54      0.53       407\n",
      "weighted avg       0.86      0.88      0.87       407\n",
      "\n",
      "\n",
      "Classification Report for k=46: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.50      0.40      0.44        30\n",
      "           4       0.70      0.90      0.79        72\n",
      "           5       0.94      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       407\n",
      "   macro avg       0.52      0.54      0.53       407\n",
      "weighted avg       0.86      0.88      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=47: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.50      0.40      0.44        30\n",
      "           4       0.71      0.90      0.79        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       407\n",
      "   macro avg       0.52      0.54      0.53       407\n",
      "weighted avg       0.86      0.88      0.87       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=48: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.48      0.37      0.42        30\n",
      "           4       0.71      0.90      0.79        72\n",
      "           5       0.94      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       407\n",
      "   macro avg       0.52      0.53      0.52       407\n",
      "weighted avg       0.86      0.88      0.87       407\n",
      "\n",
      "\n",
      "Classification Report for k=49: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.50      0.40      0.44        30\n",
      "           4       0.71      0.90      0.79        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       407\n",
      "   macro avg       0.52      0.54      0.53       407\n",
      "weighted avg       0.86      0.88      0.87       407\n",
      "\n",
      "\n",
      "Classification Report for k=50: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.50      0.40      0.44        30\n",
      "           4       0.70      0.90      0.79        72\n",
      "           5       0.94      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       407\n",
      "   macro avg       0.52      0.54      0.53       407\n",
      "weighted avg       0.86      0.88      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=51: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.50      0.40      0.44        30\n",
      "           4       0.69      0.90      0.78        72\n",
      "           5       0.94      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.52      0.54      0.53       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=52: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.48      0.37      0.42        30\n",
      "           4       0.69      0.90      0.78        72\n",
      "           5       0.94      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.52      0.53      0.52       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=53: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.48      0.37      0.42        30\n",
      "           4       0.69      0.92      0.79        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.52      0.53      0.52       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=54: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.45      0.33      0.38        30\n",
      "           4       0.68      0.90      0.77        72\n",
      "           5       0.94      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.52      0.51       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=55: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.45      0.33      0.38        30\n",
      "           4       0.68      0.90      0.77        72\n",
      "           5       0.94      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.52      0.51       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=56: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.48      0.37      0.42        30\n",
      "           4       0.68      0.90      0.78        72\n",
      "           5       0.94      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.52      0.53      0.52       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=57: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.48      0.37      0.42        30\n",
      "           4       0.69      0.90      0.78        72\n",
      "           5       0.94      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.52      0.53      0.52       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=58: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.48      0.37      0.42        30\n",
      "           4       0.69      0.90      0.78        72\n",
      "           5       0.94      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.52      0.53      0.52       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=59: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.45      0.33      0.38        30\n",
      "           4       0.68      0.90      0.78        72\n",
      "           5       0.94      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.53      0.52       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=60: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.45      0.33      0.38        30\n",
      "           4       0.68      0.90      0.78        72\n",
      "           5       0.94      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.53      0.52       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=61: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.45      0.33      0.38        30\n",
      "           4       0.69      0.92      0.79        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.53      0.52       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=62: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.45      0.33      0.38        30\n",
      "           4       0.69      0.92      0.79        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.53      0.52       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=63: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.45      0.33      0.38        30\n",
      "           4       0.69      0.92      0.79        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.53      0.52       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=64: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.45      0.33      0.38        30\n",
      "           4       0.69      0.92      0.79        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.53      0.52       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=65: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.43      0.30      0.35        30\n",
      "           4       0.68      0.92      0.78        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.52      0.51       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=66: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.43      0.30      0.35        30\n",
      "           4       0.68      0.92      0.78        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.52      0.51       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=67: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.43      0.30      0.35        30\n",
      "           4       0.68      0.92      0.78        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.52      0.51       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=68: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.43      0.30      0.35        30\n",
      "           4       0.67      0.92      0.78        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.52      0.51       407\n",
      "weighted avg       0.85      0.87      0.85       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=69: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.43      0.30      0.35        30\n",
      "           4       0.68      0.92      0.78        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.52      0.51       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=70: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.43      0.30      0.35        30\n",
      "           4       0.68      0.92      0.78        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.52      0.51       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=71: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.43      0.30      0.35        30\n",
      "           4       0.68      0.92      0.78        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.52      0.51       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=72: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.45      0.33      0.38        30\n",
      "           4       0.68      0.92      0.78        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.53      0.52       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n",
      "Classification Report for k=73: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.43      0.30      0.35        30\n",
      "           4       0.68      0.92      0.78        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.52      0.51       407\n",
      "weighted avg       0.85      0.87      0.86       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=74: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.43      0.30      0.35        30\n",
      "           4       0.67      0.92      0.78        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.51      0.52      0.51       407\n",
      "weighted avg       0.85      0.87      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=75: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.40      0.27      0.32        30\n",
      "           4       0.67      0.92      0.77        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.50      0.52      0.50       407\n",
      "weighted avg       0.84      0.87      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=76: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.40      0.27      0.32        30\n",
      "           4       0.66      0.92      0.77        72\n",
      "           5       0.95      0.93      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.50      0.51      0.50       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=77: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.37      0.23      0.29        30\n",
      "           4       0.66      0.92      0.77        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.50      0.51      0.50       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=78: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.92      0.76        72\n",
      "           5       0.95      0.93      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.84       407\n",
      "\n",
      "\n",
      "Classification Report for k=79: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.92      0.76        72\n",
      "           5       0.95      0.93      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.84       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=80: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.92      0.76        72\n",
      "           5       0.95      0.93      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.84       407\n",
      "\n",
      "\n",
      "Classification Report for k=81: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.92      0.77        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.51      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=82: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.92      0.76        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.84       407\n",
      "\n",
      "\n",
      "Classification Report for k=83: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.92      0.77        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.51      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=84: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.92      0.77        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.51      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=85: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.92      0.77        72\n",
      "           5       0.95      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.51      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=86: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.89      0.75        72\n",
      "           5       0.94      0.94      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.83      0.86      0.84       407\n",
      "\n",
      "\n",
      "Classification Report for k=87: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.90      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=88: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.89      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.83      0.86      0.84       407\n",
      "\n",
      "\n",
      "Classification Report for k=89: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.89      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.83      0.86      0.84       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=90: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.67      0.89      0.76        72\n",
      "           5       0.94      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=91: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.90      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=92: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.67      0.89      0.76        72\n",
      "           5       0.94      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=93: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.90      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=94: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.67      0.90      0.77        72\n",
      "           5       0.94      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.49      0.51      0.49       407\n",
      "weighted avg       0.84      0.87      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=95: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.90      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=96: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.67      0.90      0.77        72\n",
      "           5       0.94      0.95      0.95       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.49      0.51      0.49       407\n",
      "weighted avg       0.84      0.87      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=97: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.90      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=98: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.90      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=99: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.90      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=100: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.90      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=101: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.67      0.90      0.77        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=102: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.90      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       1.00      0.98      0.99       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.84      0.86      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=103: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.90      0.76        72\n",
      "           5       0.94      0.94      0.94       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.83      0.86      0.84       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=104: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.67      0.89      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.83      0.86      0.84       407\n",
      "\n",
      "\n",
      "Classification Report for k=105: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.68      0.90      0.77        72\n",
      "           5       0.94      0.95      0.95       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.49      0.51      0.49       407\n",
      "weighted avg       0.84      0.87      0.85       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=106: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.67      0.92      0.78        72\n",
      "           5       0.95      0.95      0.95       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       407\n",
      "   macro avg       0.49      0.51      0.49       407\n",
      "weighted avg       0.84      0.87      0.85       407\n",
      "\n",
      "\n",
      "Classification Report for k=107: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.67      0.89      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.83      0.86      0.84       407\n",
      "\n",
      "\n",
      "Classification Report for k=108: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.67      0.89      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.83      0.86      0.84       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=109: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.67      0.89      0.76        72\n",
      "           5       0.94      0.95      0.94       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.83      0.86      0.84       407\n",
      "\n",
      "\n",
      "Classification Report for k=110: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.88      0.75        72\n",
      "           5       0.93      0.95      0.94       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.83      0.86      0.84       407\n",
      "\n",
      "\n",
      "Classification Report for k=111: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.86      0.75        72\n",
      "           5       0.93      0.95      0.94       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.49      0.50      0.49       407\n",
      "weighted avg       0.83      0.86      0.84       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=112: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.85      0.74        72\n",
      "           5       0.92      0.95      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.48      0.50      0.48       407\n",
      "weighted avg       0.82      0.86      0.84       407\n",
      "\n",
      "\n",
      "Classification Report for k=113: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.85      0.74        72\n",
      "           5       0.92      0.95      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.48      0.50      0.48       407\n",
      "weighted avg       0.82      0.86      0.84       407\n",
      "\n",
      "\n",
      "Classification Report for k=114: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.85      0.74        72\n",
      "           5       0.92      0.95      0.94       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.48      0.50      0.49       407\n",
      "weighted avg       0.83      0.86      0.84       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=115: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.83      0.74        72\n",
      "           5       0.92      0.95      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.82      0.86      0.84       407\n",
      "\n",
      "\n",
      "Classification Report for k=116: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.83      0.74        72\n",
      "           5       0.92      0.95      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.82      0.86      0.84       407\n",
      "\n",
      "\n",
      "Classification Report for k=117: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.83      0.74        72\n",
      "           5       0.92      0.95      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.82      0.86      0.84       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=118: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.81      0.72        72\n",
      "           5       0.91      0.95      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.82      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=119: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.81      0.72        72\n",
      "           5       0.91      0.95      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.82      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=120: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.64      0.81      0.72        72\n",
      "           5       0.91      0.95      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.82      0.85      0.83       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=121: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.82      0.72        72\n",
      "           5       0.91      0.95      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.82      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=122: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.82      0.72        72\n",
      "           5       0.91      0.95      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.82      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=123: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.82      0.72        72\n",
      "           5       0.91      0.95      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.82      0.85      0.83       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=124: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.82      0.72        72\n",
      "           5       0.91      0.95      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.82      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=125: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.64      0.81      0.72        72\n",
      "           5       0.91      0.95      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.82      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=126: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.64      0.79      0.71        72\n",
      "           5       0.90      0.95      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.81      0.85      0.83       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=127: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.64      0.78      0.70        72\n",
      "           5       0.90      0.95      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.48      0.48       407\n",
      "weighted avg       0.81      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=128: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.64      0.78      0.70        72\n",
      "           5       0.90      0.95      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.48      0.48       407\n",
      "weighted avg       0.81      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=129: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.78      0.71        72\n",
      "           5       0.90      0.96      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.81      0.85      0.83       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=130: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.78      0.71        72\n",
      "           5       0.90      0.96      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.81      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=131: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.78      0.71        72\n",
      "           5       0.90      0.96      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.81      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=132: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.78      0.71        72\n",
      "           5       0.90      0.96      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.81      0.85      0.83       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=133: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.81      0.73        72\n",
      "           5       0.91      0.96      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.82      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=134: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.79      0.72        72\n",
      "           5       0.90      0.96      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.82      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=135: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.78      0.71        72\n",
      "           5       0.90      0.96      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.81      0.85      0.83       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=136: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.76      0.70        72\n",
      "           5       0.89      0.96      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.48      0.48       407\n",
      "weighted avg       0.81      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=137: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.76      0.70        72\n",
      "           5       0.89      0.96      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.48      0.48       407\n",
      "weighted avg       0.81      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=138: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.78      0.71        72\n",
      "           5       0.90      0.96      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.49      0.48       407\n",
      "weighted avg       0.81      0.85      0.83       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=139: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.64      0.74      0.68        72\n",
      "           5       0.88      0.96      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.47      0.48      0.47       407\n",
      "weighted avg       0.81      0.84      0.82       407\n",
      "\n",
      "\n",
      "Classification Report for k=140: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.63      0.71      0.67        72\n",
      "           5       0.87      0.96      0.91       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.47      0.47      0.47       407\n",
      "weighted avg       0.80      0.84      0.82       407\n",
      "\n",
      "\n",
      "Classification Report for k=141: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.64      0.74      0.68        72\n",
      "           5       0.88      0.96      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.47      0.48      0.47       407\n",
      "weighted avg       0.81      0.84      0.82       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=142: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.74      0.69        72\n",
      "           5       0.88      0.97      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.48      0.48      0.47       407\n",
      "weighted avg       0.81      0.84      0.82       407\n",
      "\n",
      "\n",
      "Classification Report for k=143: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.76      0.71        72\n",
      "           5       0.89      0.97      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.48      0.48       407\n",
      "weighted avg       0.81      0.85      0.83       407\n",
      "\n",
      "\n",
      "Classification Report for k=144: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.75      0.70        72\n",
      "           5       0.89      0.97      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.48      0.48       407\n",
      "weighted avg       0.81      0.85      0.82       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=145: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.64      0.71      0.67        72\n",
      "           5       0.87      0.97      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.47      0.47      0.47       407\n",
      "weighted avg       0.80      0.84      0.82       407\n",
      "\n",
      "\n",
      "Classification Report for k=146: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.74      0.69        72\n",
      "           5       0.88      0.97      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.48      0.48      0.47       407\n",
      "weighted avg       0.81      0.84      0.82       407\n",
      "\n",
      "\n",
      "Classification Report for k=147: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.64      0.72      0.68        72\n",
      "           5       0.88      0.97      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.47      0.48      0.47       407\n",
      "weighted avg       0.80      0.84      0.82       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=148: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.72      0.68        72\n",
      "           5       0.88      0.97      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.48      0.48      0.47       407\n",
      "weighted avg       0.81      0.84      0.82       407\n",
      "\n",
      "\n",
      "Classification Report for k=149: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.72      0.68        72\n",
      "           5       0.88      0.97      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.48      0.48      0.47       407\n",
      "weighted avg       0.81      0.84      0.82       407\n",
      "\n",
      "\n",
      "Classification Report for k=150: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.72      0.68        72\n",
      "           5       0.88      0.97      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.48      0.48      0.47       407\n",
      "weighted avg       0.81      0.84      0.82       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=151: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.65      0.71      0.68        72\n",
      "           5       0.87      0.97      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.47      0.48      0.47       407\n",
      "weighted avg       0.80      0.84      0.82       407\n",
      "\n",
      "\n",
      "Classification Report for k=152: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.72      0.69        72\n",
      "           5       0.88      0.98      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.48      0.47       407\n",
      "weighted avg       0.81      0.85      0.82       407\n",
      "\n",
      "\n",
      "Classification Report for k=153: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.72      0.69        72\n",
      "           5       0.88      0.98      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.48      0.47       407\n",
      "weighted avg       0.81      0.85      0.82       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=154: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.20      0.25        30\n",
      "           4       0.66      0.72      0.69        72\n",
      "           5       0.88      0.98      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       407\n",
      "   macro avg       0.48      0.48      0.47       407\n",
      "weighted avg       0.81      0.85      0.82       407\n",
      "\n",
      "\n",
      "Classification Report for k=155: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.29      0.17      0.21        30\n",
      "           4       0.64      0.69      0.67        72\n",
      "           5       0.87      0.98      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.47      0.47      0.46       407\n",
      "weighted avg       0.80      0.84      0.81       407\n",
      "\n",
      "\n",
      "Classification Report for k=156: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.29      0.17      0.21        30\n",
      "           4       0.64      0.71      0.67        72\n",
      "           5       0.87      0.97      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.47      0.47      0.46       407\n",
      "weighted avg       0.80      0.84      0.82       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=157: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.31      0.17      0.22        30\n",
      "           4       0.62      0.68      0.65        72\n",
      "           5       0.87      0.97      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       407\n",
      "   macro avg       0.46      0.47      0.46       407\n",
      "weighted avg       0.79      0.83      0.81       407\n",
      "\n",
      "\n",
      "Classification Report for k=158: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.31      0.17      0.22        30\n",
      "           4       0.63      0.71      0.67        72\n",
      "           5       0.87      0.97      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.47      0.47      0.46       407\n",
      "weighted avg       0.80      0.84      0.82       407\n",
      "\n",
      "\n",
      "Classification Report for k=159: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.31      0.17      0.22        30\n",
      "           4       0.64      0.72      0.68        72\n",
      "           5       0.88      0.98      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.47      0.47      0.47       407\n",
      "weighted avg       0.80      0.84      0.82       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=160: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.33      0.13      0.19        30\n",
      "           4       0.61      0.72      0.66        72\n",
      "           5       0.88      0.98      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.47      0.47      0.46       407\n",
      "weighted avg       0.80      0.84      0.81       407\n",
      "\n",
      "\n",
      "Classification Report for k=161: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.38      0.10      0.16        30\n",
      "           4       0.58      0.71      0.64        72\n",
      "           5       0.88      0.98      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.47      0.46      0.45       407\n",
      "weighted avg       0.79      0.84      0.81       407\n",
      "\n",
      "\n",
      "Classification Report for k=162: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.25      0.03      0.06        30\n",
      "           4       0.57      0.72      0.63        72\n",
      "           5       0.88      0.98      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       407\n",
      "   macro avg       0.45      0.45      0.43       407\n",
      "weighted avg       0.79      0.84      0.80       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=163: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.55      0.71      0.62        72\n",
      "           5       0.88      0.98      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       407\n",
      "   macro avg       0.40      0.44      0.42       407\n",
      "weighted avg       0.76      0.83      0.79       407\n",
      "\n",
      "\n",
      "Classification Report for k=164: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.55      0.69      0.61        72\n",
      "           5       0.87      0.99      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       407\n",
      "   macro avg       0.40      0.44      0.42       407\n",
      "weighted avg       0.76      0.83      0.79       407\n",
      "\n",
      "\n",
      "Classification Report for k=165: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.55      0.69      0.61        72\n",
      "           5       0.87      0.99      0.93       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       407\n",
      "   macro avg       0.40      0.44      0.42       407\n",
      "weighted avg       0.76      0.83      0.79       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=166: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.54      0.67      0.60        72\n",
      "           5       0.86      0.99      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       407\n",
      "   macro avg       0.40      0.44      0.42       407\n",
      "weighted avg       0.75      0.83      0.79       407\n",
      "\n",
      "\n",
      "Classification Report for k=167: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.54      0.68      0.60        72\n",
      "           5       0.87      0.98      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       407\n",
      "   macro avg       0.40      0.44      0.42       407\n",
      "weighted avg       0.76      0.83      0.79       407\n",
      "\n",
      "\n",
      "Classification Report for k=168: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.53      0.65      0.58        72\n",
      "           5       0.86      0.98      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       407\n",
      "   macro avg       0.40      0.44      0.41       407\n",
      "weighted avg       0.75      0.82      0.78       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=169: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.52      0.65      0.58        72\n",
      "           5       0.86      0.98      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       407\n",
      "   macro avg       0.40      0.44      0.41       407\n",
      "weighted avg       0.75      0.82      0.78       407\n",
      "\n",
      "\n",
      "Classification Report for k=170: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.53      0.67      0.59        72\n",
      "           5       0.86      0.99      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       407\n",
      "   macro avg       0.40      0.44      0.42       407\n",
      "weighted avg       0.75      0.83      0.79       407\n",
      "\n",
      "\n",
      "Classification Report for k=171: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.53      0.67      0.59        72\n",
      "           5       0.86      0.99      0.92       172\n",
      "           6       0.99      0.98      0.98       121\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       407\n",
      "   macro avg       0.40      0.44      0.42       407\n",
      "weighted avg       0.75      0.83      0.79       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=172: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.54      0.68      0.60        72\n",
      "           5       0.86      0.99      0.92       172\n",
      "           6       0.99      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       407\n",
      "   macro avg       0.40      0.44      0.42       407\n",
      "weighted avg       0.75      0.83      0.79       407\n",
      "\n",
      "\n",
      "Classification Report for k=173: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.53      0.67      0.59        72\n",
      "           5       0.86      0.99      0.92       172\n",
      "           6       0.99      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       407\n",
      "   macro avg       0.40      0.44      0.41       407\n",
      "weighted avg       0.75      0.82      0.78       407\n",
      "\n",
      "\n",
      "Classification Report for k=174: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.53      0.67      0.59        72\n",
      "           5       0.86      0.99      0.92       172\n",
      "           6       0.99      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       407\n",
      "   macro avg       0.40      0.44      0.41       407\n",
      "weighted avg       0.75      0.82      0.78       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=175: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.52      0.65      0.58        72\n",
      "           5       0.85      0.99      0.92       172\n",
      "           6       0.99      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       407\n",
      "   macro avg       0.39      0.43      0.41       407\n",
      "weighted avg       0.75      0.82      0.78       407\n",
      "\n",
      "\n",
      "Classification Report for k=176: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.52      0.64      0.57        72\n",
      "           5       0.85      0.99      0.92       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       407\n",
      "   macro avg       0.39      0.43      0.41       407\n",
      "weighted avg       0.75      0.82      0.78       407\n",
      "\n",
      "\n",
      "Classification Report for k=177: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.52      0.65      0.58        72\n",
      "           5       0.85      0.99      0.92       172\n",
      "           6       0.99      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       407\n",
      "   macro avg       0.39      0.43      0.41       407\n",
      "weighted avg       0.75      0.82      0.78       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=178: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.51      0.61      0.55        72\n",
      "           5       0.84      0.99      0.91       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       407\n",
      "   macro avg       0.39      0.43      0.41       407\n",
      "weighted avg       0.74      0.82      0.78       407\n",
      "\n",
      "\n",
      "Classification Report for k=179: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.51      0.64      0.57        72\n",
      "           5       0.85      0.99      0.91       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       407\n",
      "   macro avg       0.39      0.43      0.41       407\n",
      "weighted avg       0.75      0.82      0.78       407\n",
      "\n",
      "\n",
      "Classification Report for k=180: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.51      0.61      0.55        72\n",
      "           5       0.84      0.99      0.91       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       407\n",
      "   macro avg       0.39      0.43      0.41       407\n",
      "weighted avg       0.74      0.82      0.78       407\n",
      "\n",
      "\n",
      "Classification Report for k=181: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.51      0.62      0.56        72\n",
      "           5       0.85      0.99      0.91       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.82      0.82      0.82       407\n",
      "   macro avg       0.39      0.43      0.41       407\n",
      "weighted avg       0.74      0.82      0.78       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=182: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.60      0.54        72\n",
      "           5       0.84      0.99      0.91       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.43      0.41       407\n",
      "weighted avg       0.74      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=183: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.60      0.54        72\n",
      "           5       0.84      0.99      0.91       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.43      0.41       407\n",
      "weighted avg       0.74      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=184: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.58      0.53        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.74      0.81      0.77       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=185: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.58      0.54        72\n",
      "           5       0.83      0.99      0.91       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.74      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=186: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.58      0.53        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.74      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=187: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.58      0.54        72\n",
      "           5       0.83      0.99      0.91       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.74      0.81      0.77       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=188: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.58      0.54        72\n",
      "           5       0.83      0.99      0.91       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.74      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=189: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.58      0.54        72\n",
      "           5       0.83      0.99      0.91       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.74      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=190: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.57      0.53        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.73      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=191: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.57      0.53        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.73      0.81      0.77       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=192: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.48      0.57      0.52        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.73      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=193: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.57      0.53        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.73      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=194: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.58      0.53        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.74      0.81      0.77       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=195: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.57      0.53        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.73      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=196: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.58      0.53        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.96      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.73      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=197: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.48      0.57      0.52        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.96      0.98       121\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       407\n",
      "   macro avg       0.38      0.42      0.40       407\n",
      "weighted avg       0.73      0.80      0.76       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=198: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.58      0.54        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.96      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.74      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=199: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.57      0.53        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.73      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=200: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.57      0.53        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.96      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.73      0.81      0.77       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=201: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.49      0.57      0.53        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.96      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.39      0.42      0.40       407\n",
      "weighted avg       0.73      0.81      0.77       407\n",
      "\n",
      "\n",
      "Classification Report for k=202: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.48      0.56      0.52        72\n",
      "           5       0.82      0.99      0.90       172\n",
      "           6       1.00      0.96      0.98       121\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       407\n",
      "   macro avg       0.38      0.42      0.40       407\n",
      "weighted avg       0.73      0.80      0.76       407\n",
      "\n",
      "\n",
      "Classification Report for k=203: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.48      0.56      0.52        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.38      0.42      0.40       407\n",
      "weighted avg       0.73      0.81      0.76       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=204: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.48      0.56      0.52        72\n",
      "           5       0.82      0.99      0.90       172\n",
      "           6       1.00      0.96      0.98       121\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       407\n",
      "   macro avg       0.38      0.42      0.40       407\n",
      "weighted avg       0.73      0.80      0.76       407\n",
      "\n",
      "\n",
      "Classification Report for k=205: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.48      0.56      0.52        72\n",
      "           5       0.83      0.99      0.90       172\n",
      "           6       1.00      0.97      0.98       121\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       407\n",
      "   macro avg       0.38      0.42      0.40       407\n",
      "weighted avg       0.73      0.81      0.76       407\n",
      "\n",
      "\n",
      "Classification Report for k=206: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.48      0.54      0.51        72\n",
      "           5       0.82      0.99      0.90       172\n",
      "           6       1.00      0.96      0.98       121\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       407\n",
      "   macro avg       0.38      0.42      0.40       407\n",
      "weighted avg       0.73      0.80      0.76       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=207: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.48      0.54      0.51        72\n",
      "           5       0.82      0.99      0.90       172\n",
      "           6       1.00      0.96      0.98       121\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       407\n",
      "   macro avg       0.38      0.42      0.40       407\n",
      "weighted avg       0.73      0.80      0.76       407\n",
      "\n",
      "\n",
      "Classification Report for k=208: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.47      0.53      0.50        72\n",
      "           5       0.82      1.00      0.90       172\n",
      "           6       1.00      0.96      0.98       121\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       407\n",
      "   macro avg       0.38      0.41      0.40       407\n",
      "weighted avg       0.73      0.80      0.76       407\n",
      "\n",
      "\n",
      "Classification Report for k=209: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.47      0.53      0.50        72\n",
      "           5       0.81      1.00      0.90       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       407\n",
      "   macro avg       0.38      0.41      0.40       407\n",
      "weighted avg       0.72      0.80      0.76       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=210: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.47      0.51      0.49        72\n",
      "           5       0.81      1.00      0.89       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       407\n",
      "   macro avg       0.38      0.41      0.39       407\n",
      "weighted avg       0.72      0.80      0.75       407\n",
      "\n",
      "\n",
      "Classification Report for k=211: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.47      0.53      0.50        72\n",
      "           5       0.81      1.00      0.90       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       407\n",
      "   macro avg       0.38      0.41      0.40       407\n",
      "weighted avg       0.72      0.80      0.76       407\n",
      "\n",
      "\n",
      "Classification Report for k=212: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.47      0.53      0.50        72\n",
      "           5       0.81      1.00      0.90       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       407\n",
      "   macro avg       0.38      0.41      0.40       407\n",
      "weighted avg       0.72      0.80      0.76       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=213: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.47      0.53      0.50        72\n",
      "           5       0.81      1.00      0.90       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       407\n",
      "   macro avg       0.38      0.41      0.40       407\n",
      "weighted avg       0.72      0.80      0.76       407\n",
      "\n",
      "\n",
      "Classification Report for k=214: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.47      0.51      0.49        72\n",
      "           5       0.81      1.00      0.89       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       407\n",
      "   macro avg       0.38      0.41      0.39       407\n",
      "weighted avg       0.72      0.80      0.75       407\n",
      "\n",
      "\n",
      "Classification Report for k=215: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.47      0.51      0.49        72\n",
      "           5       0.81      1.00      0.89       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       407\n",
      "   macro avg       0.38      0.41      0.39       407\n",
      "weighted avg       0.72      0.80      0.75       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=216: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.46      0.50      0.48        72\n",
      "           5       0.80      1.00      0.89       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       407\n",
      "   macro avg       0.38      0.41      0.39       407\n",
      "weighted avg       0.72      0.79      0.75       407\n",
      "\n",
      "\n",
      "Classification Report for k=217: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.46      0.50      0.48        72\n",
      "           5       0.80      1.00      0.89       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       407\n",
      "   macro avg       0.38      0.41      0.39       407\n",
      "weighted avg       0.72      0.79      0.75       407\n",
      "\n",
      "\n",
      "Classification Report for k=218: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.45      0.49      0.47        72\n",
      "           5       0.80      1.00      0.89       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       407\n",
      "   macro avg       0.38      0.41      0.39       407\n",
      "weighted avg       0.72      0.79      0.75       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=219: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.44      0.46      0.45        72\n",
      "           5       0.79      1.00      0.88       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       407\n",
      "   macro avg       0.37      0.40      0.38       407\n",
      "weighted avg       0.71      0.79      0.74       407\n",
      "\n",
      "\n",
      "Classification Report for k=220: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.43      0.44      0.44        72\n",
      "           5       0.79      1.00      0.88       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       407\n",
      "   macro avg       0.37      0.40      0.38       407\n",
      "weighted avg       0.71      0.78      0.74       407\n",
      "\n",
      "\n",
      "Classification Report for k=221: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.42      0.43      0.43        72\n",
      "           5       0.79      1.00      0.88       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       407\n",
      "   macro avg       0.37      0.40      0.38       407\n",
      "weighted avg       0.70      0.78      0.74       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=222: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.42      0.43      0.43        72\n",
      "           5       0.79      1.00      0.88       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       407\n",
      "   macro avg       0.37      0.40      0.38       407\n",
      "weighted avg       0.70      0.78      0.74       407\n",
      "\n",
      "\n",
      "Classification Report for k=223: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.42      0.43      0.43        72\n",
      "           5       0.79      1.00      0.88       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       407\n",
      "   macro avg       0.37      0.40      0.38       407\n",
      "weighted avg       0.70      0.78      0.74       407\n",
      "\n",
      "\n",
      "Classification Report for k=224: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.42      0.43      0.43        72\n",
      "           5       0.79      1.00      0.88       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       407\n",
      "   macro avg       0.37      0.40      0.38       407\n",
      "weighted avg       0.70      0.78      0.74       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=225: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.42      0.43      0.43        72\n",
      "           5       0.79      1.00      0.88       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       407\n",
      "   macro avg       0.37      0.40      0.38       407\n",
      "weighted avg       0.70      0.78      0.74       407\n",
      "\n",
      "\n",
      "Classification Report for k=226: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.42      0.42      0.42        72\n",
      "           5       0.78      1.00      0.88       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       407\n",
      "   macro avg       0.37      0.39      0.38       407\n",
      "weighted avg       0.70      0.78      0.73       407\n",
      "\n",
      "\n",
      "Classification Report for k=227: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.42      0.42      0.42        72\n",
      "           5       0.78      1.00      0.88       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       407\n",
      "   macro avg       0.37      0.39      0.38       407\n",
      "weighted avg       0.70      0.78      0.73       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=228: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.41      0.40      0.41        72\n",
      "           5       0.77      1.00      0.87       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       407\n",
      "   macro avg       0.36      0.39      0.38       407\n",
      "weighted avg       0.70      0.78      0.73       407\n",
      "\n",
      "\n",
      "Classification Report for k=229: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.40      0.39      0.39        72\n",
      "           5       0.77      1.00      0.87       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       407\n",
      "   macro avg       0.36      0.39      0.37       407\n",
      "weighted avg       0.70      0.77      0.73       407\n",
      "\n",
      "\n",
      "Classification Report for k=230: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.42      0.42      0.42        72\n",
      "           5       0.78      1.00      0.88       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       407\n",
      "   macro avg       0.37      0.39      0.38       407\n",
      "weighted avg       0.70      0.78      0.73       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=231: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.41      0.39      0.40        72\n",
      "           5       0.77      1.00      0.87       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       407\n",
      "   macro avg       0.36      0.39      0.37       407\n",
      "weighted avg       0.70      0.77      0.73       407\n",
      "\n",
      "\n",
      "Classification Report for k=232: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.41      0.39      0.40        72\n",
      "           5       0.77      1.00      0.87       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       407\n",
      "   macro avg       0.36      0.39      0.37       407\n",
      "weighted avg       0.70      0.77      0.73       407\n",
      "\n",
      "\n",
      "Classification Report for k=233: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.41      0.39      0.40        72\n",
      "           5       0.77      1.00      0.87       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       407\n",
      "   macro avg       0.36      0.39      0.37       407\n",
      "weighted avg       0.70      0.77      0.73       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=234: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.38      0.35      0.36        72\n",
      "           5       0.76      1.00      0.86       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       407\n",
      "   macro avg       0.36      0.38      0.37       407\n",
      "weighted avg       0.69      0.77      0.72       407\n",
      "\n",
      "\n",
      "Classification Report for k=235: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.37      0.33      0.35        72\n",
      "           5       0.76      1.00      0.86       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       407\n",
      "   macro avg       0.35      0.38      0.36       407\n",
      "weighted avg       0.68      0.76      0.72       407\n",
      "\n",
      "\n",
      "Classification Report for k=236: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.35      0.31      0.33        72\n",
      "           5       0.75      1.00      0.86       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       407\n",
      "   macro avg       0.35      0.38      0.36       407\n",
      "weighted avg       0.68      0.76      0.71       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=237: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.35      0.31      0.33        72\n",
      "           5       0.75      1.00      0.86       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       407\n",
      "   macro avg       0.35      0.38      0.36       407\n",
      "weighted avg       0.68      0.76      0.71       407\n",
      "\n",
      "\n",
      "Classification Report for k=238: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.33      0.28      0.30        72\n",
      "           5       0.74      1.00      0.85       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       407\n",
      "   macro avg       0.35      0.37      0.35       407\n",
      "weighted avg       0.67      0.75      0.70       407\n",
      "\n",
      "\n",
      "Classification Report for k=239: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.31      0.25      0.27        72\n",
      "           5       0.74      1.00      0.85       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       407\n",
      "   macro avg       0.34      0.37      0.35       407\n",
      "weighted avg       0.66      0.75      0.70       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=240: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.31      0.25      0.27        72\n",
      "           5       0.74      1.00      0.85       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       407\n",
      "   macro avg       0.34      0.37      0.35       407\n",
      "weighted avg       0.66      0.75      0.70       407\n",
      "\n",
      "\n",
      "Classification Report for k=241: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.31      0.25      0.27        72\n",
      "           5       0.74      1.00      0.85       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       407\n",
      "   macro avg       0.34      0.37      0.35       407\n",
      "weighted avg       0.66      0.75      0.70       407\n",
      "\n",
      "\n",
      "Classification Report for k=242: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.29      0.24      0.26        72\n",
      "           5       0.74      1.00      0.85       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       407\n",
      "   macro avg       0.34      0.36      0.35       407\n",
      "weighted avg       0.66      0.75      0.69       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=243: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.31      0.25      0.27        72\n",
      "           5       0.74      1.00      0.85       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       407\n",
      "   macro avg       0.34      0.37      0.35       407\n",
      "weighted avg       0.66      0.75      0.70       407\n",
      "\n",
      "\n",
      "Classification Report for k=244: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.29      0.24      0.26        72\n",
      "           5       0.74      1.00      0.85       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       407\n",
      "   macro avg       0.34      0.36      0.35       407\n",
      "weighted avg       0.66      0.75      0.69       407\n",
      "\n",
      "\n",
      "Classification Report for k=245: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.28      0.22      0.25        72\n",
      "           5       0.73      1.00      0.85       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       407\n",
      "   macro avg       0.34      0.36      0.34       407\n",
      "weighted avg       0.66      0.74      0.69       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=246: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.27      0.21      0.23        72\n",
      "           5       0.73      1.00      0.84       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       407\n",
      "   macro avg       0.33      0.36      0.34       407\n",
      "weighted avg       0.65      0.74      0.69       407\n",
      "\n",
      "\n",
      "Classification Report for k=247: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.25      0.18      0.21        72\n",
      "           5       0.72      1.00      0.84       172\n",
      "           6       1.00      0.95      0.97       121\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       407\n",
      "   macro avg       0.33      0.36      0.34       407\n",
      "weighted avg       0.64      0.74      0.68       407\n",
      "\n",
      "\n",
      "Classification Report for k=248: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.22      0.15      0.18        72\n",
      "           5       0.71      1.00      0.83       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       407\n",
      "   macro avg       0.32      0.35      0.33       407\n",
      "weighted avg       0.64      0.73      0.67       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=249: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.20      0.14      0.16        72\n",
      "           5       0.71      1.00      0.83       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       407\n",
      "   macro avg       0.32      0.35      0.33       407\n",
      "weighted avg       0.63      0.73      0.67       407\n",
      "\n",
      "\n",
      "Classification Report for k=250: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.18      0.12      0.15        72\n",
      "           5       0.70      1.00      0.83       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.31      0.34      0.32       407\n",
      "weighted avg       0.63      0.72      0.66       407\n",
      "\n",
      "\n",
      "Classification Report for k=251: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.17      0.11      0.13        72\n",
      "           5       0.70      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.31      0.34      0.32       407\n",
      "weighted avg       0.62      0.72      0.66       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=252: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.19      0.12      0.15        72\n",
      "           5       0.70      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.31      0.34      0.32       407\n",
      "weighted avg       0.63      0.72      0.66       407\n",
      "\n",
      "\n",
      "Classification Report for k=253: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.17      0.11      0.13        72\n",
      "           5       0.70      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.31      0.34      0.32       407\n",
      "weighted avg       0.62      0.72      0.66       407\n",
      "\n",
      "\n",
      "Classification Report for k=254: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.17      0.11      0.13        72\n",
      "           5       0.70      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.31      0.34      0.32       407\n",
      "weighted avg       0.62      0.72      0.66       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=255: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.15      0.10      0.12        72\n",
      "           5       0.70      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.31      0.34      0.32       407\n",
      "weighted avg       0.62      0.72      0.66       407\n",
      "\n",
      "\n",
      "Classification Report for k=256: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.15      0.10      0.12        72\n",
      "           5       0.70      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.31      0.34      0.32       407\n",
      "weighted avg       0.62      0.72      0.66       407\n",
      "\n",
      "\n",
      "Classification Report for k=257: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.15      0.10      0.12        72\n",
      "           5       0.70      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.31      0.34      0.32       407\n",
      "weighted avg       0.62      0.72      0.66       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=258: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.15      0.10      0.12        72\n",
      "           5       0.70      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.31      0.34      0.32       407\n",
      "weighted avg       0.62      0.72      0.66       407\n",
      "\n",
      "\n",
      "Classification Report for k=259: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.15      0.10      0.12        72\n",
      "           5       0.70      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.31      0.34      0.32       407\n",
      "weighted avg       0.62      0.72      0.66       407\n",
      "\n",
      "\n",
      "Classification Report for k=260: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.15      0.10      0.12        72\n",
      "           5       0.70      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.31      0.34      0.32       407\n",
      "weighted avg       0.62      0.72      0.66       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=261: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.15      0.10      0.12        72\n",
      "           5       0.70      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.31      0.34      0.32       407\n",
      "weighted avg       0.62      0.72      0.66       407\n",
      "\n",
      "\n",
      "Classification Report for k=262: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.16      0.10      0.12        72\n",
      "           5       0.69      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.31      0.34      0.32       407\n",
      "weighted avg       0.62      0.72      0.66       407\n",
      "\n",
      "\n",
      "Classification Report for k=263: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.14      0.08      0.10        72\n",
      "           5       0.69      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.30      0.34      0.32       407\n",
      "weighted avg       0.61      0.72      0.65       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=264: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.14      0.08      0.10        72\n",
      "           5       0.69      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       407\n",
      "   macro avg       0.30      0.34      0.32       407\n",
      "weighted avg       0.61      0.72      0.65       407\n",
      "\n",
      "\n",
      "Classification Report for k=265: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.12      0.07      0.09        72\n",
      "           5       0.69      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.30      0.34      0.31       407\n",
      "weighted avg       0.61      0.71      0.65       407\n",
      "\n",
      "\n",
      "Classification Report for k=266: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.12      0.07      0.09        72\n",
      "           5       0.69      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.30      0.34      0.31       407\n",
      "weighted avg       0.61      0.71      0.65       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=267: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.12      0.07      0.09        72\n",
      "           5       0.69      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.30      0.34      0.31       407\n",
      "weighted avg       0.61      0.71      0.65       407\n",
      "\n",
      "\n",
      "Classification Report for k=268: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.12      0.07      0.09        72\n",
      "           5       0.69      1.00      0.82       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.30      0.34      0.31       407\n",
      "weighted avg       0.61      0.71      0.65       407\n",
      "\n",
      "\n",
      "Classification Report for k=269: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.12      0.07      0.09        72\n",
      "           5       0.69      1.00      0.81       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.30      0.34      0.31       407\n",
      "weighted avg       0.61      0.71      0.65       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=270: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.12      0.07      0.09        72\n",
      "           5       0.69      1.00      0.81       172\n",
      "           6       1.00      0.94      0.97       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.30      0.34      0.31       407\n",
      "weighted avg       0.61      0.71      0.65       407\n",
      "\n",
      "\n",
      "Classification Report for k=271: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.12      0.07      0.09        72\n",
      "           5       0.68      1.00      0.81       172\n",
      "           6       1.00      0.93      0.97       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.30      0.33      0.31       407\n",
      "weighted avg       0.61      0.71      0.64       407\n",
      "\n",
      "\n",
      "Classification Report for k=272: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.12      0.07      0.09        72\n",
      "           5       0.68      1.00      0.81       172\n",
      "           6       1.00      0.93      0.97       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.30      0.33      0.31       407\n",
      "weighted avg       0.61      0.71      0.64       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=273: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.10      0.06      0.07        72\n",
      "           5       0.68      1.00      0.81       172\n",
      "           6       1.00      0.93      0.97       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.30      0.33      0.31       407\n",
      "weighted avg       0.60      0.71      0.64       407\n",
      "\n",
      "\n",
      "Classification Report for k=274: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.11      0.06      0.07        72\n",
      "           5       0.67      1.00      0.80       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.30      0.33      0.31       407\n",
      "weighted avg       0.60      0.71      0.64       407\n",
      "\n",
      "\n",
      "Classification Report for k=275: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.11      0.06      0.07        72\n",
      "           5       0.67      1.00      0.80       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.30      0.33      0.31       407\n",
      "weighted avg       0.60      0.71      0.64       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=276: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.11      0.06      0.07        72\n",
      "           5       0.67      1.00      0.80       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.30      0.33      0.31       407\n",
      "weighted avg       0.60      0.71      0.64       407\n",
      "\n",
      "\n",
      "Classification Report for k=277: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.08      0.04      0.06        72\n",
      "           5       0.67      1.00      0.80       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.29      0.33      0.30       407\n",
      "weighted avg       0.59      0.71      0.63       407\n",
      "\n",
      "\n",
      "Classification Report for k=278: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.08      0.04      0.06        72\n",
      "           5       0.66      1.00      0.80       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       407\n",
      "   macro avg       0.29      0.33      0.30       407\n",
      "weighted avg       0.59      0.71      0.63       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=279: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.06      0.03      0.04        72\n",
      "           5       0.66      1.00      0.80       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.29      0.33      0.30       407\n",
      "weighted avg       0.59      0.70      0.63       407\n",
      "\n",
      "\n",
      "Classification Report for k=280: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.06      0.03      0.04        72\n",
      "           5       0.66      1.00      0.80       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.29      0.33      0.30       407\n",
      "weighted avg       0.59      0.70      0.63       407\n",
      "\n",
      "\n",
      "Classification Report for k=281: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.06      0.03      0.04        72\n",
      "           5       0.66      1.00      0.80       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.29      0.33      0.30       407\n",
      "weighted avg       0.59      0.70      0.63       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=282: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.06      0.03      0.04        72\n",
      "           5       0.66      1.00      0.80       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.29      0.33      0.30       407\n",
      "weighted avg       0.59      0.70      0.63       407\n",
      "\n",
      "\n",
      "Classification Report for k=283: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.03      0.01      0.02        72\n",
      "           5       0.66      1.00      0.79       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.28      0.32      0.30       407\n",
      "weighted avg       0.58      0.70      0.62       407\n",
      "\n",
      "\n",
      "Classification Report for k=284: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.06      0.03      0.04        72\n",
      "           5       0.66      1.00      0.79       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.29      0.33      0.30       407\n",
      "weighted avg       0.59      0.70      0.63       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=285: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.65      1.00      0.79       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.28      0.32      0.29       407\n",
      "weighted avg       0.57      0.70      0.62       407\n",
      "\n",
      "\n",
      "Classification Report for k=286: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.65      1.00      0.79       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.28      0.32      0.29       407\n",
      "weighted avg       0.57      0.70      0.62       407\n",
      "\n",
      "\n",
      "Classification Report for k=287: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.64      1.00      0.78       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.57      0.70      0.61       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=288: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.63      1.00      0.78       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.57      0.70      0.61       407\n",
      "\n",
      "\n",
      "Classification Report for k=289: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.63      1.00      0.77       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.56      0.70      0.61       407\n",
      "\n",
      "\n",
      "Classification Report for k=290: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.63      1.00      0.78       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.57      0.70      0.61       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=291: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.63      1.00      0.77       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.56      0.70      0.61       407\n",
      "\n",
      "\n",
      "Classification Report for k=292: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.63      1.00      0.77       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.56      0.70      0.61       407\n",
      "\n",
      "\n",
      "Classification Report for k=293: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.63      1.00      0.77       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.56      0.70      0.61       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=294: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.63      1.00      0.77       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.56      0.70      0.61       407\n",
      "\n",
      "\n",
      "Classification Report for k=295: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.63      1.00      0.77       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.56      0.70      0.61       407\n",
      "\n",
      "\n",
      "Classification Report for k=296: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.63      1.00      0.77       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.56      0.70      0.61       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=297: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.63      1.00      0.77       172\n",
      "           6       1.00      0.93      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.56      0.70      0.61       407\n",
      "\n",
      "\n",
      "Classification Report for k=298: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.62      1.00      0.76       172\n",
      "           6       1.00      0.92      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.56      0.70      0.61       407\n",
      "\n",
      "\n",
      "Classification Report for k=299: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.62      1.00      0.77       172\n",
      "           6       1.00      0.92      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.56      0.70      0.61       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=300: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.61      1.00      0.76       172\n",
      "           6       1.00      0.92      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.56      0.70      0.61       407\n",
      "\n",
      "\n",
      "Classification Report for k=301: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.61      1.00      0.76       172\n",
      "           6       1.00      0.92      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.56      0.70      0.61       407\n",
      "\n",
      "\n",
      "Classification Report for k=302: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.61      1.00      0.75       172\n",
      "           6       1.00      0.92      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.29       407\n",
      "weighted avg       0.55      0.70      0.60       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=303: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.60      1.00      0.75       172\n",
      "           6       1.00      0.92      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.28       407\n",
      "weighted avg       0.55      0.70      0.60       407\n",
      "\n",
      "\n",
      "Classification Report for k=304: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.59      1.00      0.74       172\n",
      "           6       1.00      0.92      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.28       407\n",
      "weighted avg       0.55      0.70      0.60       407\n",
      "\n",
      "\n",
      "Classification Report for k=305: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.59      1.00      0.74       172\n",
      "           6       1.00      0.92      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.28       407\n",
      "weighted avg       0.55      0.70      0.60       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=306: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.59      1.00      0.74       172\n",
      "           6       1.00      0.92      0.96       121\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       407\n",
      "   macro avg       0.27      0.32      0.28       407\n",
      "weighted avg       0.55      0.70      0.60       407\n",
      "\n",
      "\n",
      "Classification Report for k=307: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.91      0.95       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n",
      "Classification Report for k=308: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.91      0.95       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=309: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.91      0.95       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n",
      "Classification Report for k=310: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.91      0.95       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=311: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.90      0.95       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n",
      "Classification Report for k=312: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.91      0.95       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=313: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.90      0.95       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n",
      "Classification Report for k=314: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.90      0.95       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=315: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.90      0.95       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n",
      "Classification Report for k=316: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.89      0.94       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=317: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.90      0.95       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n",
      "Classification Report for k=318: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.90      0.95       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=319: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.89      0.94       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n",
      "Classification Report for k=320: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.58      1.00      0.73       172\n",
      "           6       1.00      0.89      0.94       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.32      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=321: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.57      1.00      0.73       172\n",
      "           6       1.00      0.88      0.94       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.31      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n",
      "Classification Report for k=322: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.57      1.00      0.73       172\n",
      "           6       1.00      0.88      0.94       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.31      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=323: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.57      1.00      0.73       172\n",
      "           6       1.00      0.88      0.94       121\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       407\n",
      "   macro avg       0.26      0.31      0.28       407\n",
      "weighted avg       0.54      0.69      0.59       407\n",
      "\n",
      "\n",
      "Classification Report for k=324: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.57      1.00      0.73       172\n",
      "           6       1.00      0.88      0.93       121\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       407\n",
      "   macro avg       0.26      0.31      0.28       407\n",
      "weighted avg       0.54      0.68      0.59       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=325: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.57      1.00      0.73       172\n",
      "           6       1.00      0.88      0.93       121\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       407\n",
      "   macro avg       0.26      0.31      0.28       407\n",
      "weighted avg       0.54      0.68      0.59       407\n",
      "\n",
      "\n",
      "Classification Report for k=326: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.57      1.00      0.73       172\n",
      "           6       1.00      0.87      0.93       121\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       407\n",
      "   macro avg       0.26      0.31      0.28       407\n",
      "weighted avg       0.54      0.68      0.58       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=327: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.57      1.00      0.73       172\n",
      "           6       1.00      0.87      0.93       121\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       407\n",
      "   macro avg       0.26      0.31      0.28       407\n",
      "weighted avg       0.54      0.68      0.58       407\n",
      "\n",
      "\n",
      "Classification Report for k=328: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.57      1.00      0.72       172\n",
      "           6       1.00      0.86      0.92       121\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       407\n",
      "   macro avg       0.26      0.31      0.27       407\n",
      "weighted avg       0.54      0.68      0.58       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=329: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.57      1.00      0.72       172\n",
      "           6       1.00      0.86      0.92       121\n",
      "\n",
      "   micro avg       0.68      0.68      0.68       407\n",
      "   macro avg       0.26      0.31      0.27       407\n",
      "weighted avg       0.54      0.68      0.58       407\n",
      "\n",
      "\n",
      "Classification Report for k=330: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.56      1.00      0.72       172\n",
      "           6       1.00      0.84      0.91       121\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       407\n",
      "   macro avg       0.26      0.31      0.27       407\n",
      "weighted avg       0.54      0.67      0.58       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=331: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.56      1.00      0.72       172\n",
      "           6       1.00      0.84      0.91       121\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       407\n",
      "   macro avg       0.26      0.31      0.27       407\n",
      "weighted avg       0.54      0.67      0.58       407\n",
      "\n",
      "\n",
      "Classification Report for k=332: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.56      1.00      0.72       172\n",
      "           6       1.00      0.84      0.91       121\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       407\n",
      "   macro avg       0.26      0.31      0.27       407\n",
      "weighted avg       0.54      0.67      0.58       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=333: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.56      1.00      0.72       172\n",
      "           6       1.00      0.83      0.90       121\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.67      0.57       407\n",
      "\n",
      "\n",
      "Classification Report for k=334: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.56      1.00      0.72       172\n",
      "           6       1.00      0.82      0.90       121\n",
      "\n",
      "   micro avg       0.67      0.67      0.67       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.67      0.57       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=335: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.56      1.00      0.72       172\n",
      "           6       1.00      0.81      0.89       121\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.66      0.57       407\n",
      "\n",
      "\n",
      "Classification Report for k=336: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.80      0.89       121\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.66      0.57       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=337: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.79      0.88       121\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.66      0.56       407\n",
      "\n",
      "\n",
      "Classification Report for k=338: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.79      0.88       121\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.66      0.56       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=339: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.79      0.88       121\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.66      0.56       407\n",
      "\n",
      "\n",
      "Classification Report for k=340: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.79      0.88       121\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.66      0.56       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=341: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.79      0.88       121\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.66      0.56       407\n",
      "\n",
      "\n",
      "Classification Report for k=342: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.79      0.88       121\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.66      0.56       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=343: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.79      0.88       121\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.66      0.56       407\n",
      "\n",
      "\n",
      "Classification Report for k=344: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.79      0.88       121\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.66      0.56       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=345: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.79      0.88       121\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.66      0.56       407\n",
      "\n",
      "\n",
      "Classification Report for k=346: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.79      0.88       121\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       407\n",
      "   macro avg       0.26      0.30      0.27       407\n",
      "weighted avg       0.53      0.66      0.56       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=347: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.78      0.87       121\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       407\n",
      "   macro avg       0.26      0.30      0.26       407\n",
      "weighted avg       0.53      0.65      0.56       407\n",
      "\n",
      "\n",
      "Classification Report for k=348: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.77      0.87       121\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       407\n",
      "   macro avg       0.26      0.29      0.26       407\n",
      "weighted avg       0.53      0.65      0.56       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=349: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.55      1.00      0.71       172\n",
      "           6       1.00      0.76      0.86       121\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       407\n",
      "   macro avg       0.26      0.29      0.26       407\n",
      "weighted avg       0.53      0.65      0.56       407\n",
      "\n",
      "\n",
      "Classification Report for k=350: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.54      1.00      0.70       172\n",
      "           6       1.00      0.74      0.85       121\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       407\n",
      "   macro avg       0.26      0.29      0.26       407\n",
      "weighted avg       0.53      0.64      0.55       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=351: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.54      1.00      0.70       172\n",
      "           6       1.00      0.74      0.85       121\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       407\n",
      "   macro avg       0.26      0.29      0.26       407\n",
      "weighted avg       0.53      0.64      0.55       407\n",
      "\n",
      "\n",
      "Classification Report for k=352: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.54      1.00      0.70       172\n",
      "           6       1.00      0.73      0.84       121\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       407\n",
      "   macro avg       0.26      0.29      0.26       407\n",
      "weighted avg       0.53      0.64      0.55       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=353: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.53      1.00      0.69       172\n",
      "           6       1.00      0.69      0.81       121\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       407\n",
      "   macro avg       0.26      0.28      0.25       407\n",
      "weighted avg       0.52      0.63      0.54       407\n",
      "\n",
      "\n",
      "Classification Report for k=354: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.52      1.00      0.69       172\n",
      "           6       1.00      0.65      0.79       121\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       407\n",
      "   macro avg       0.25      0.28      0.25       407\n",
      "weighted avg       0.52      0.62      0.53       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=355: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.52      1.00      0.68       172\n",
      "           6       1.00      0.63      0.77       121\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       407\n",
      "   macro avg       0.25      0.27      0.24       407\n",
      "weighted avg       0.52      0.61      0.52       407\n",
      "\n",
      "\n",
      "Classification Report for k=356: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.52      1.00      0.68       172\n",
      "           6       1.00      0.62      0.77       121\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       407\n",
      "   macro avg       0.25      0.27      0.24       407\n",
      "weighted avg       0.52      0.61      0.52       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=357: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.51      1.00      0.68       172\n",
      "           6       1.00      0.60      0.75       121\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       407\n",
      "   macro avg       0.25      0.27      0.24       407\n",
      "weighted avg       0.51      0.60      0.51       407\n",
      "\n",
      "\n",
      "Classification Report for k=358: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.51      1.00      0.68       172\n",
      "           6       1.00      0.59      0.74       121\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       407\n",
      "   macro avg       0.25      0.26      0.24       407\n",
      "weighted avg       0.51      0.60      0.51       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=359: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.50      1.00      0.67       172\n",
      "           6       1.00      0.55      0.71       121\n",
      "\n",
      "   micro avg       0.58      0.58      0.58       407\n",
      "   macro avg       0.25      0.26      0.23       407\n",
      "weighted avg       0.51      0.58      0.49       407\n",
      "\n",
      "\n",
      "Classification Report for k=360: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.50      1.00      0.66       172\n",
      "           6       1.00      0.50      0.66       121\n",
      "\n",
      "   micro avg       0.57      0.57      0.57       407\n",
      "   macro avg       0.25      0.25      0.22       407\n",
      "weighted avg       0.51      0.57      0.48       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=361: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.48      1.00      0.65       172\n",
      "           6       1.00      0.42      0.59       121\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       407\n",
      "   macro avg       0.25      0.24      0.21       407\n",
      "weighted avg       0.50      0.55      0.45       407\n",
      "\n",
      "\n",
      "Classification Report for k=362: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.48      1.00      0.65       172\n",
      "           6       1.00      0.39      0.56       121\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       407\n",
      "   macro avg       0.25      0.23      0.20       407\n",
      "weighted avg       0.50      0.54      0.44       407\n",
      "\n",
      "\n",
      "Classification Report for k=363: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.47      1.00      0.64       172\n",
      "           6       1.00      0.31      0.48       121\n",
      "\n",
      "   micro avg       0.52      0.52      0.52       407\n",
      "   macro avg       0.24      0.22      0.19       407\n",
      "weighted avg       0.49      0.52      0.41       407\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for k=364: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.46      1.00      0.63       172\n",
      "           6       1.00      0.27      0.43       121\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       407\n",
      "   macro avg       0.24      0.21      0.18       407\n",
      "weighted avg       0.49      0.50      0.39       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=365: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.46      1.00      0.63       172\n",
      "           6       1.00      0.25      0.40       121\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       407\n",
      "   macro avg       0.24      0.21      0.17       407\n",
      "weighted avg       0.49      0.50      0.38       407\n",
      "\n",
      "\n",
      "Classification Report for k=366: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.44      1.00      0.61       172\n",
      "           6       1.00      0.16      0.27       121\n",
      "\n",
      "   micro avg       0.47      0.47      0.47       407\n",
      "   macro avg       0.24      0.19      0.15       407\n",
      "weighted avg       0.48      0.47      0.34       407\n",
      "\n",
      "\n",
      "Classification Report for k=367: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.44      1.00      0.61       172\n",
      "           6       1.00      0.12      0.21       121\n",
      "\n",
      "   micro avg       0.46      0.46      0.46       407\n",
      "   macro avg       0.24      0.19      0.14       407\n",
      "weighted avg       0.48      0.46      0.32       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=368: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.43      1.00      0.60       172\n",
      "           6       1.00      0.07      0.14       121\n",
      "\n",
      "   micro avg       0.44      0.44      0.44       407\n",
      "   macro avg       0.24      0.18      0.12       407\n",
      "weighted avg       0.48      0.44      0.30       407\n",
      "\n",
      "\n",
      "Classification Report for k=369: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.43      1.00      0.60       172\n",
      "           6       1.00      0.04      0.08       121\n",
      "\n",
      "   micro avg       0.43      0.43      0.43       407\n",
      "   macro avg       0.24      0.17      0.11       407\n",
      "weighted avg       0.48      0.43      0.28       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=370: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.43      1.00      0.60       172\n",
      "           6       1.00      0.02      0.05       121\n",
      "\n",
      "   micro avg       0.43      0.43      0.43       407\n",
      "   macro avg       0.24      0.17      0.11       407\n",
      "weighted avg       0.48      0.43      0.27       407\n",
      "\n",
      "\n",
      "Classification Report for k=371: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=372: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=373: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=374: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=375: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=376: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=377: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=378: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=379: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=380: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=381: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=382: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=383: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=384: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=385: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=386: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=387: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=388: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=389: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=390: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=391: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=392: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=393: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=394: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=395: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=396: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=397: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=398: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=399: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=400: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=401: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=402: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=403: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=404: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=405: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=406: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=407: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=408: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=409: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=410: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=411: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=412: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=413: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=414: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=415: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=416: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=417: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=418: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=419: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=420: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=421: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=422: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=423: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=424: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=425: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=426: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=427: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=428: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=429: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=430: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=431: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=432: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=433: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=434: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=435: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=436: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=437: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=438: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=439: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=440: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=441: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=442: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=443: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=444: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=445: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=446: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=447: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=448: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=449: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=450: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=451: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=452: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=453: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=454: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=455: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=456: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=457: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=458: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=459: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=460: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=461: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=462: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=463: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=464: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=465: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=466: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=467: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=468: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=469: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=470: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=471: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=472: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=473: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=474: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=475: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=476: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=477: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=478: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=479: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=480: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=481: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=482: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=483: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=484: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=485: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=486: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=487: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=488: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=489: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=490: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=491: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=492: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=493: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=494: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=495: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=496: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=497: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=498: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=499: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=500: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=501: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=502: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=503: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=504: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=505: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=506: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=507: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=508: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=509: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=510: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=511: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=512: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=513: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=514: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=515: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=516: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=517: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=518: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=519: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=520: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=521: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=522: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=523: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=524: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=525: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=526: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=527: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=528: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=529: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=530: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=531: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=532: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=533: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=534: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=535: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=536: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=537: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=538: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=539: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=540: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=541: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=542: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=543: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=544: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=545: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=546: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=547: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=548: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=549: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=550: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=551: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=552: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=553: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=554: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=555: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=556: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=557: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=558: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=559: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=560: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=561: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=562: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=563: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=564: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=565: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=566: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=567: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=568: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=569: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=570: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=571: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=572: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=573: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=574: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=575: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=576: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=577: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=578: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=579: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=580: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=581: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=582: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=583: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=584: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=585: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=586: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=587: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=588: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=589: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=590: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=591: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=592: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=593: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=594: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=595: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=596: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=597: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=598: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=599: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=600: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=601: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=602: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=603: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=604: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for k=605: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=606: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=607: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n",
      "Classification Report for k=608: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        72\n",
      "           5       0.42      1.00      0.59       172\n",
      "           6       0.00      0.00      0.00       121\n",
      "\n",
      "   micro avg       0.42      0.42      0.42       407\n",
      "   macro avg       0.07      0.17      0.10       407\n",
      "weighted avg       0.18      0.42      0.25       407\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "k_range = range(1,len(df_x_train.iloc[:,0]))\n",
    "scores = {}\n",
    "scores_list = [] \n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(df_x_train, df_y_train)\n",
    "    y_pred = knn.predict(df_x_test)\n",
    "    scores[k] = metrics.accuracy_score(df_y_test, y_pred)\n",
    "    scores_list.append(metrics.accuracy_score(df_y_test, y_pred))\n",
    "    print(\"Classification Report for k={}: \\n{}\\n\".format(k, classification_report(df_y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Testing Accuracy')"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl81NW9//HXJwtZICFAwr4rsrghRtw3UItLtbVWcbu1tcX2p1Vbb3u17fW29trWtrdqq7Xu2s0Fu0gtFXeLikhQQUFBVglhCWvCGpJ8fn/MN8MQsgww30xm8n4+HvPIdznfmc/RkM+cc77nfM3dERERAchIdgAiItJ+KCmIiEiUkoKIiEQpKYiISJSSgoiIRCkpiIhIlJKCiIhEKSmIiEiUkoKIiERlJTuAfVVcXOyDBw9OdhgiIill9uzZ69y9pLVyKZcUBg8eTFlZWbLDEBFJKWa2PJ5y6j4SEZEoJQUREYlSUhARkSglBRERiVJSEBGRKCUFERGJUlIQEZGoDpUU1m3ZyT/nrkp2GCIi7VbKTV47EN+ZPIdXF1Ry5IDT6d8tv9lya6t38McZy6mpc4q7dOLqk4ZgZm0YqYhIcnSYpPDvhZW8uqASgMWVW1tMCjc9PYfpn6yL7p9wUDGj+haGHqOISLJ1mO6jhWuqo9sLVlfx6fpt3PfaYtydFRt2by+u3LJHQgB4a/G6xm8nIpKWOkxS6JKzu1E0uayc7/3tA+54/mPmVVQx6Q+zueP5jynfuJ0f/WN+tNxdl4ymf7c83l+xCYBl67by06kfUVNb3+bxi4i0hQ7TfdQ5Jil8snYLmRmRMYK3l6xn+fqtAFz3xHvMWbGJb5x2EP81YQQAz81dxXNzV7FuywzmV1RRtaOWAd3zueK4QW1fCRGRkHWclkLunvlv5abtALy1eD3bauoAmBO0CA7r2zVarjC47u0lG6jaURtsrw89XhGRZOg4SSFnz6RQHfyBf+XjtXuVPaRXl+j2pFOHRrc7ZUX+c63YsC2MEEVEkq7jdB912l1VM3CHIcWdWbou0nV0/biD6d65E59u2M7Qkt1JYUTvQl769qn88e3l/ODckdw6ZR7Pf7i6zeMXEWkLoSYFM5sA3A1kAg+5+88anR8EPAKUABuAK9y9PIxYCmK6j759xiF8tLqKq08ayozF6ygd3J3jhvZo9tqDe3bhh+cfCsCAbvls2FrDhq01dO/cKYxQRUSSJrSkYGaZwL3AmUA5MMvMprj7/JhivwR+7+6Pm9k44KfAlWHEEzvQ/M3xw6LbRw/qtk/vc9rwEu54/mP++PZyro95HxGRdBDmmMJYYJG7L3H3GuBJ4IJGZUYBLwfbrzZxPmE652Qm5H1G9inkmMHdeOmjNQl5PxGR9iTMpNAPWBGzXx4cizUH+EKw/XmgwMz26scxs0lmVmZmZZWVlfsVTE5WJCl0y8/er+tjnXBQMXPLN3Pfa4sP+L1ERNqTMJNCU4sFeaP9/wRONbP3gFOBlUDtXhe5P+Dupe5eWlJSst8BPXrVMfzjmyft9/UNrjw+Mkdh+if7l6BERNqrMAeay4EBMfv9gYrYAu5eAVwIYGZdgC+4++awAjp9RM+EvE9xlxwuLu3P395bSV29RyfCiYikujBbCrOAYWY2xMw6AROBKbEFzKzYzBpiuIXInUgpYWSfQnbVOd95Zk6yQxERSZjQkoK71wLXAdOAj4Cn3X2emd1mZucHxU4DFpjZQqAXcHtY8STaxaUDOOngYv7+3krWVO1IdjgiIgkR6oxmd5/q7oe4+0Hufntw7FZ3nxJsP+Puw4IyX3X3nWHGk0idc7K4+ewR1Du8uUirqIpIeugwy1yEYVSfQnp07qSnuYlI2lBSOAAZGcaXThjMyx+v5ZE3lvLO0g3JDklE5IAoKRygcw7vA8Btz83n4vtnaAVVEUlpSgoH6KCSznTLz2bskO70Kszh9n9+xAvzVrN1Zy2Ty1awcE01T5et4Il3PtXqqiLS7pl74/lk7VtpaamXlZUlO4w9bK+pIzvTeGZ2OTf/9QMATh5WvNdjPQ/p1YUrjhuEO9TWO13zsrnwqH5kaJ6DiITMzGa7e2lr5TrM0tlhyusUWUJj4tiBjB5YxIS7pu+REL54dH9KB3fjv/7yAbc+O2+Pa3OzMzjviL5tGq+ISHOUFBJsRO9Cxgws4pM1W5h6w8l079yJ/E6ZmBnnHtGXKx+eyeH9unLTmcO5+P4Z/OqFhUw4tDdZmc335L22YC1zyzdzyiEljB5QBMCWnbU8+sZSThpWzFED922lVxGR5qj7KAT19Y5Dq8tfTJu3mmv+MJvPHNqLn3z+cB56Yyk1tfUY0LMwh54Fucwp38Sjby6LXvOVE4cAsLZ6B8/NXcWwnl148dunhlcZEUkL6j5KonjHCM4a1YsRvQuYNm8NldU7effTTXuVycnaswUxuWwFO2vrqamrB2Bx5RZu/+d8vn3m8Gg3lojI/lJSSCIzY/LXj2f0bS9GE8IlpQN4qiyy4vjQks788epj6VuUt8d1c1Zs4v/96V2OGljE+ys28eD0pRTld+La0w9u8zqISHpRUkiygtxsLjlmAG98so4vnziYq04YHE0Kr9x0WpPXHDmgiDdvHhfdv/qxWdz/+mIyzOjfLY/PHqmBaxHZPxpTaId+9cIC+nfP5+LSAa0XBuZXVHHOr6dH9885vDc/+8IRFOYe+AOFRCQ9xDumoMlr7dC3zxoed0IAGNW3kOvHHUz/bnkM6pHP1A9W88pHa5ssu7ZqB9f++V3WVmtlVxHZm1oKaaau3hnz4xfZvH0X/bvlUZSfzWeP6Ms1px4EwG9fW8TPn1/A2Yf15r4rjk5ytCLSVtRS6KAyM4zrxw8DoHzjdnbVOr98YQGvL6zknLun87vgudIvzl/DDU++x/2vL6Zi03Yue/BtPl2vZThEOjoNNKehq08aQkFuFp07ZXH0oG6c+otX+cpjs8jNyuC0ET05emA3fjL1I559v4Jn36+g3uGtxev572c/5PGvjAXgl9MW8Lf3VnLB6L58d8KIJNdIRNqKuo86gGffX8n0T9ZxxsheTDisNwBT5lRw/RPvATB2cHfeWbZ72e/C3CyqdtQC0K8oj6euOY6vPl7GnZeMZmSfwravgIgcMHUfSdQFo/vxyy8eGU0IAOcf2Zf7Lh8DwDvLNuwx+3r7rjoABvfIZ+Wm7Tz5zgo+Xl3Nf/1lbtsGLiJtTkmhAxszaPeaSd8+8xAAehfmMvN7Z/Df543i5rMj3Ub3vLoIgI9WVbGztq7tAxWRNqMxhQ6sV2FudHvSKUMp7tKJC8f0Jzszg6tPGkJNbT39ivJYuWk7RfnZbNq2i6semcUTk45LYtQiEia1FDq45755ElOvP5nszAwuOWYg2TGrtXbKyuBbQQvihvHDGNazC7OXb2TV5u3JCldEQqaWQgd3WL+uLZ6/8Kh+FOZmMX5kL4YUd+aqR2dx/E9fYfLXj+eYwd3bKEoRaStqKUiLMjKMsw7tTWaGccqwEu69bAzZmcZjby6jescu5pZvYtO2mmSHKSIJopaCxC0jwzj3iD489MYS/vnBKl6cv4aaunpKCnKYct2J9Oma1/qbiEi7ppaC7LO7LzkKgJq6eob3KqCyeidf/N0M3lq8jvr61Jr3IiJ7UlKQfTawRz7HD+0BwPfPHckPzh1J+cbtXPbgTO54/mMlBpEUphnNsl+qduxi5cbtjOhdgJmxYHU1n7nr30Bk6e67Jx61x51MIpJcmtEsoSrMzWZkn0LMIjOhh/cuYPyIngBM/WA1Uz9YlczwRGQ/aaBZEuZ3Vx7Ntpo6jrrtBX4y9SO21dSxc1cdZsbFpQP0DGmRFKCkIAmTnZlB17wMLhzTn2dml3PLXz+InvvHnApOG15CZkYGYwYW8e6nm7jiuIEU6OlwIu1KqEnBzCYAdwOZwEPu/rNG5wcCjwNFQZmb3X1qmDFJ+H5x0RHsqqvn2fcrOHlYMSUFOfz13ZWULd+4R7nn5lYwbkRPcrIy+NIJg5UgRNqB0JKCmWUC9wJnAuXALDOb4u7zY4r9AHja3e8zs1HAVGBwWDFJ2zAz7p54FHdPPCp6rEtOFqs27yDDYNq8NQDMq6hiXkUVAHX1cMMZw5ISr4jsFmZLYSywyN2XAJjZk8AFQGxScKBhgf6uQEWI8UgS3XbBYQCs2LCNZeu28atLjuSfc1fx2+BJcH9/fyV9inL36dnUIpJ4od2SamYXARPc/avB/pXAse5+XUyZPsALQDegM3CGu89u6X11S2r6uf/1xfz2tcVs3r4r2t1001nD6VekGdIiidIebkm1Jo41zkCXAo+5e3/gHOAPZrZXTGY2yczKzKyssrIyhFAlma459SBe/PYpAEz/ZB3/mFPBBfe8qWdGiyRBmEmhHIjtC+jP3t1DVwNPA7j7DCAXKG78Ru7+gLuXuntpSUlJSOFKMvUsyOXHFxzK104ewg/OHcW6LTv57D1vsLhyS7JDE+lQwhxTmAUMM7MhwEpgInBZozKfAuOBx8xsJJGkoKZAB3Xl8YOj23nZmXz3L3P52b8+5sH/aLXFKyIJElpScPdaM7sOmEbkdtNH3H2emd0GlLn7FOAm4EEz+xaRrqWrPNXW3ZBQXHzMAD5ZW81jby1je02dJr6JtJFQ5ykEcw6mNjp2a8z2fODEMGOQ1HXSsBIenL6UGUvWMW5Er2SHI9IhaO0jabeOHdKdXoU53PfaYtSAFGkbrSYFM/u6mbX8zEaREORmZ/LNccOYtWwjR/zoBY7+8Yu8uWhdssMSSWvxdB8NBt41s5lExgVeCjckkd0uOWYAldU72bx9F9Pmrebyh2Zy1MAiuuZl89iXxyY7PJG0E9fktWDuwNnAl4EjgSeIJIhloUbXBE1e67jmrNjExAfeZvuuOgDevHmcJriJxCmhk9fcvR5YFrzqgT7As2b20wOIUWSfHDmgiJ9eeHh0/6Q7XuG1BWuTGJFI+mm1+8jM/h9wFVAFPAx83913Bq2HRcAtoUYoEuOC0X3Jzsxgw7YafjRlHu8s3cBpw3smOyyRtBHPmEJ/YGLDwnYN3L3ezM4PJyyRppkZ5x7RB4A/zFjGgtXVyQ1IJM3E0330NyDaRjezAjMrBXD3D8MKTKQ1I/sU8t6KTWyvqUt2KCJpI56k8AAQuzLZVuD+cMIRid+lYweyYWsN/5ijFddFEiWepJARDDQD0UFnPSJLku7YId3pWZDDg9OXUFNb3/oFItKqeJLCUjP7hpllmlmGmV1L5C4kkaQyM04aVswna7cwefaKZIcjkhbiSQrXEFnJdE3wOhX4WphBicTrJ58/nOxMY/pCzXQWSYRW7z5y9zXARW0Qi8g+y83O5HOj+/HC/DXU1TuZGU0920lE4hXPPIUcIvMUDiXyvAMA3H1SeGGJxO/Eg4uZPLucX724gN5d87hgdF8KczXsJbI/4uk++j2R9Y/OA2YCBwE7QoxJZJ+cNKyYgpws7n11Mf/99w+5+S9zkx2SSMqKJykc4u63AFvc/WFgAnBYuGGJxK+4Sw7v3nom15w6FIB/fbhaz3cW2U/xJIVdwc9NwSMzC4BB4YUksu+yMzO45eyRvPO98eRkZXDXSwuTHZJISoonKTxsZt2A/yHyaM2FwP+FGpXIfupZmMvFpQN47oNV7Nilmc4i+6rFpGBmmcA6d9/o7q+6+0B3L3b337ZRfCL77PThPamprWf28o3JDkUk5bSYFNy9DrixjWIRSYjSwd0AeH/FpiRHIpJ64uk+mmZmN5pZHzMrbHiFHpnIfirIzaZfUZ5WUBXZD/EsnX1N8POmmGMODEx8OCKJMaJ3AfNXVeHumGlCm0i8Wm0puPuAJl5KCNKunTq8hEVrt/DmovXJDkUkpcQzo/mypo67+58TH45IYlxyzADuf30JVzw8k/OP7MvdE0erxSASh3jGFE6OeZ0J/BSthSTtXE5WJjeMHwbAlDkVXPS7GdTXe5KjEmn/4lkQ7xux+8GchcfCCkgkUS4c04+Kzdt55eO1zF6+kcN/OI2MoLUwsm8hT3ztOC2gJ9KIue/btyczywI+cPeR4YTUstLSUi8rK0vGR0uKqqt3fvf6YtZvqQFg47Ya/vbeSgb1yOf5G04hM8PIyjAylCAkjZnZbHcvba1cPGMKfyNytxFEupsOBZ49sPBE2k5mhnHt6QdH992d/E6Z/Gnmp4y89XkABvfI55/Xn0znnHhuyBNJX/H8C7gnZrsWWO7uy8IJRyR8Zsb/fu4wjujflXVbatiwtYaH31jKyT9/lbduHkdudmayQxRJmniSwifAWnffAWBmeWY2wN31/ENJWWbGJcdE7qx2dwpys7jrpU+477XFfOWkIXTN0/MYpGOK5+6jvwKxT0WvB/4Sz5ub2QQzW2Bmi8zs5ibO32lm7wevhWamdQmkzZkZN55xCCcPK+bulz/hpDteYem6rckOSyQp4kkKWe5e07Dj7juBnNYuChbTuxc4GxgFXGpmo2LLuPu33H20u48GfkMkAYkkxZ2XjOZH5x9K9Y5azv31dGYsXs/SdVtZW6VnSknHEU/30XozO8fdpwKY2XnAhjiuGwsscvclwXVPAhcA85spfymR5blFkqK4Sw5fOmEwXXKyuGnyHC598O3ouU9uP5vszHi+Q4mktniSwjeAP5vZvUTuQloHXBHHdf2A2HGHcuDYpgqa2SBgCPBKHO8rEqovHN2fEX0KWFK5lW8+8R4Av5+xnIHd8/col2Fw/EE9yO+kO5YkfcQzeW0hUGpmRcF+vP3+Td303dykiInAM8FS3Xu/kdkkYBLAwIFadknCd2jfrhzatytDijvzuXvf5MfPNd3APfuw3kw4rHd0v3+3fI4e1K2twhRJuHjmKfwY+L+GZBDMaL7R3Vvr6ikHBsTs9wcqmik7Ebi2uTdy9weAByAyea21mEUS5bB+XXn9u6ezcWvNXuf+MGM5T5Wt4F8fro4ey8wwbj1vFMVdcigpyGHskO5tGa7IAWt1RrOZvefuRzU69q67j2nluiwij+4cD6wEZgGXufu8RuWGE3nM5xCPY3q1ZjRLe1FbV8+nG7ZFm79bd9Zy+YMzqd5ZGy3zvXNGUJCbTc+CHMaP7JWcQEVI4IxmINPMOjXcgWRmuUCn1i5y91ozu47IH/xM4BF3n2dmtwFl7j4lKHop8GQ8CUGkPcnKzGBoSZc9jr11yzjWVO3grDv/Tb3DT6Z+HD33/XNG8rVThrZ1mCL7JJ6WwveAzwCPEBkTuBqY5u4/CT+8vamlIKmgtq6e2nrnkTeXcu8ri9haExkuu+aUoVx+7CAG9shv5R1EEivelkJcC+IFt6GeQWTw+AV3/+eBh7h/lBQkFVXt2MW5v57Oig3b6VmQwxOTjuOgRq0MkTDFmxTiuvHa3Z9z9xvd/QZgnZndfcARinQghbnZTP/uOH524eGsrd7JRfe9xcerq5Idlshe4koKZnaYmd1uZouBXwJLww1LJD1NHDuQOy85ko3bdvHF+2Ywr2JzskMS2UOzScHMhprZ98zsQ+AhIpPWst39ZHe/q80iFEkznz+qP/deNobqnbU8PF3fr6R9aamlsIjIAPOF7n6cu99JZOlsETlA5x7Rh/OO6MML89fwP89+iG6+k/aipaRwCZHWwctm9lszO5WmZymLyH647NiB9CrM4fEZy1lcqVVZpX1oNim4+2R3/wKRFU5nArcAvc3sN2Y2rq0CFElXJxxUzKNXjQXg3wsrkxyNSESrA83uXu3uj7v7BCLLVnwM/DDswEQ6goE98jmif1ceeXMpNbX1rV8gErJ9WgvY3de5+73ufkpYAYl0NDedNZzyjdt5atanyQ5FZN+Sgogk3inDihk7pDu/fmUR22uaXChYpM0oKYgkmZnxnc8Mp7J6J6Nve4FDb32e389YluywpIOKa5mL9kTLXEi6+uPby1m+fiszlqznw5VVmEHfrnlMveFkuuZlJzs8SXEJWyXVzDay98NxNgNlwHfcfdl+RSgie7jiuEEAlG/cxuSycnbsquP+fy/hwX8v4T8/MzzJ0UlHEc/S2b8B1gB/JjJPYSJQQmRy26PA6aFFJ9IB9e+Wz7fOPASAis07eOTNpXzphMGUFOQkOTLpCOIZUzgruONoo7tvcPffAme7+58APVZKJETfOmMYO2vrNcYgbSbeBfEubLTdMLNZN1aLhGhoSRfGDCzS5DZpM/EkhSuAr5nZBjNbD3wNuNLM8oEbQ41ORDjhoGI+WLmZT9dvS3Yo0gHEM6N5kbuf7e7d3b1HsL3Q3be5++ttEaRIR3bZsQPJzszgrpcXJjsU6QDiufuoGPgKMDi2vLtPCi8sEWnQqzCXy44dyONvLeO2Cw6jS04894eI7J94uo+eBXoBbwAvx7xEpI2MHlBEvUPFpu3JDkXSXDxfOTq7+02hRyIizepXlAdEksIhvQqSHI2ks3haCv8ys7NCj0REmtU3mhR2JDkSSXfxJIWvA8+b2ZbgDqSNZrYh7MBEZLeeBTlkZpi6jyR08XQfFYcehYi0KCszg96FuUoKErpmk4KZDXP3T4BDmykyN5yQRKQpfbrmUrFZSUHC1VJL4WbgauDeJs45oAftiLShvkV5vL9iU7LDkDTXbFJw96uDzXHuviv2nJlpHV+RNta3KI9/fbiK+nonI8Nav0BkP8Qz0DwzzmMiEqKB3fPZVees1LiChKilMYWeQB8gz8wOZ/cieIVAfhvEJiIxhvfuAsDCNdUM6K5/ghKOlsYUziWyvEV/IuMKDUmhGvjvkOMSkUYaJq3Nr6hi/MheSY5G0lWz3Ufu/qi7nwxc7e6nuPvJwescd58cz5ub2QQzW2Bmi8zs5mbKXGxm881snpn9eT/rIZL2CnKzGTOwiCfe+ZTaOq1aL+GIZ0yhp5kVApjZ78zsHTMb39pFZpZJpIVxNjAKuNTMRjUqMwy4BTjR3Q9FS3GLtOjSsQOp2LyDZVpGW0IST1KY5O5VwVIX/YFvAD+P47qxwCJ3X+LuNcCTwAWNynwNuNfdNwK4+9r4QxfpeEb2KQRgwerqJEci6SqepODBz7OBR919dpzX9QNWxOyXB8diHQIcYmZvmtnbZjYhjvcV6bAO7tmFDIO5KzVfQcIRzx/3OWY2FfgskcXxurA7UbSkqRupG1+XBQwDTgMuBR4ys6K93shskpmVmVlZZaUeSygdV252JuNG9OSJmZ9SU6txBUm8eJLCl4EfAmPdfRuQS2Smc2vKgQEx+/2BiibKPOvuu9x9KbCASJLYg7s/4O6l7l5aUlISx0eLpK8zR/Wiakcta6u1YqokXjyP46wDhhIZSwDIi+c6YBYwzMyGmFknYCIwpVGZvwOnQ/QJb4cAS+ILXaRj6lmQC0Bl9c4kRyLpqNU/7mZ2D5E/3FcEh7YCv2vtOnevBa4DpgEfAU+7+zwzu83Mzg+KTQPWm9l84FXgO+6+ft+rIdJxlBTkAEoKEo54ls4+wd3HmNl7AO6+Ifjm3yp3nwpMbXTs1phtB74dvEQkDg1JYa2SgoQgnm6gXWaWQTBIbGY9AI1wiSRJj86dMFNLQcLRbFIws4ZWxL3AX4ASM/sR8AZwRxvEJiJNyMrMoEfnTlRuUVKQxGup++gdYIy7/97MZgNnELnN9Ivu/mGbRCciTSruksPaKiUFSbyWkkJ0noG7zwPmhR+OiMSjpCBHLQUJRUtJocTMmh0AdvdfhRCPiMShpCCHJZVbkx2GpKGWkkIm0IWmZyaLSBL1LMilsnon7o6Z/olK4rSUFFa5+21tFomIxK24Sydq6uqp2lFL1zw9HVcSp6VbUvX1Q6SdKsiNfJ+r3rGrlZIi+6alpNDqMxNEJDkKciOtg+odtUmORNJNS09e29CWgYhI/Ha3FJQUJLHimdEsIu3M7paCuo8ksZQURFJQQ0thy061FCSxlBREUlBDUqhS95EkmJKCSAoqVPeRhERJQSQF5WRlkJ1pGmiWhFNSEElBZkZxlxzWVOmRnJJYSgoiKWpA93zKN2xPdhiSZpQURFLUgG75fLphW7LDkDSjpCCSogZ0z2NN9Q521tYlOxRJI0oKIimqR5cc3GHzNt2BJImjpCCSogo1V0FCoKQgkqK0UqqEQUlBJEU1rH+kpS4kkZQURFKUVkqVMCgpiKSoLjnqPpLEU1IQSVF60I6EQUlBJEU1tBR095EkkpKCSIrKzDAKcrOo2q7uI0kcJQWRFNazQIviSWIpKYiksF6FuaxWUpAECjUpmNkEM1tgZovM7OYmzl9lZpVm9n7w+mqY8Yikm96FuazZrKQgiZMV1hubWSZwL3AmUA7MMrMp7j6/UdGn3P26sOIQSWe9uuaytnon9fVORoYlOxxJA2G2FMYCi9x9ibvXAE8CF4T4eSIdTr+iPGrrnVXqQpIECTMp9ANWxOyXB8ca+4KZzTWzZ8xsQIjxiKSdQ3oVALBwdXWSI5F0EWZSaKot6432/wEMdvcjgJeAx5t8I7NJZlZmZmWVlZUJDlMkdQ0PksLHSgqSIGEmhXIg9pt/f6AitoC7r3f3ncHug8DRTb2Ruz/g7qXuXlpSUhJKsCKpqGt+Nl3zslm1WY/llMQIMynMAoaZ2RAz6wRMBKbEFjCzPjG75wMfhRiPSFrqkpPF1p16+pokRmh3H7l7rZldB0wDMoFH3H2emd0GlLn7FOB6MzsfqAU2AFeFFY9IusrvlMm2Gi11IYkRWlIAcPepwNRGx26N2b4FuCXMGETSXeecLLbWqKUgiaEZzSIprnNOJtv0oB1JECUFkRSX30ktBUkcJQWRFNdZYwqSQEoKIimuc04WW9V9JAmipCCS4jrrllRJICUFkRSX3ymT7bvqqKtvvGCAyL5TUhBJcQ2P5dyqcQVJACUFkRRXUpADwNqqna2UFGmdkoJIiutdmAug9Y8kIZQURFJc36I8AFbpCWySAEoKIimuV0NLYZOSghw4JQWRFNcpK4PiLjnqPpKEUFIQSQN9i3LVfSQJoaQgkgZ6F+aqpSAJoaQgkgb6FuVpTEESQklBJA306ZpL9c5aqnfsSnYokuKUFETSQO+ukTuQVmtcQQ6QkoJIGmiYq1ChpCAHSElBJA00zGpercFmOUBKCiJBFgboAAAJYklEQVRpoHfXXMygQoPNcoCUFETSQHZmBoO65zOvoirZoUiKU1IQSRPHH9SDmUvWU1tXn+xQJIUpKYikidJB3aneWcuy9duSHYqkMCUFkTQxvHcBAAtWVyc5EkllWckOQEQS4+CeXcgw+J8p87jrpYXJDkdCcP34YXz2yL6hfoaSgkiayM3O5KazhjOvYnOyQ5GQdM3LDv0zlBRE0si1px+c7BAkxWlMQUREopQUREQkSklBRESiQk0KZjbBzBaY2SIzu7mFcheZmZtZaZjxiIhIy0JLCmaWCdwLnA2MAi41s1FNlCsArgdmhhWLiIjEJ8yWwlhgkbsvcfca4EnggibK/Rj4OaCVvEREkizMpNAPWBGzXx4cizKzo4AB7v5ciHGIiEicwkwK1sQxj540ywDuBG5q9Y3MJplZmZmVVVZWJjBEERGJFebktXJgQMx+f6AiZr8AOAx4zcwAegNTzOx8dy+LfSN3fwB4AMDMKs1s+X7GVAys289r2xPVo31RPdqfdKlLIusxKJ5C5u6tl9oPZpYFLATGAyuBWcBl7j6vmfKvAf/ZOCEkOKYyd0/5O5xUj/ZF9Wh/0qUuyahHaN1H7l4LXAdMAz4Cnnb3eWZ2m5mdH9bniojI/gt17SN3nwpMbXTs1mbKnhZmLCIi0rqONqP5gWQHkCCqR/uierQ/6VKXNq9HaGMKIiKSejpaS0FERFrQIZJCvGswtRdm9oiZrTWzD2OOdTezF83sk+Bnt+C4mdmvg7rNNbMxyYt8NzMbYGavmtlHZjbPzG4IjqdUPQDMLNfM3jGzOUFdfhQcH2JmM4O6PGVmnYLjOcH+ouD84GTGH8vMMs3sPTN7LthPuToAmNkyM/vAzN43s7LgWCr+bhWZ2TNm9nHwb+X4ZNcj7ZNCvGswtTOPARMaHbsZeNndhwEvB/sQqdew4DUJuK+NYmxNLXCTu48EjgOuDf67p1o9AHYC49z9SGA0MMHMjgPuAO4M6rIRuDoofzWw0d0PJjJB844kxNycG4jcDdggFevQ4HR3Hx1zy2Yq/m7dDTzv7iOAI4n8v0luPdw9rV/A8cC0mP1bgFuSHVcccQ8GPozZXwD0Cbb7AAuC7fuBS5sq155ewLPAmWlQj3zgXeBYIpOKshr/nhG5Dfv4YDsrKGftIPb+RP7IjAOeI7LqQErVIaYuy4DiRsdS6ncLKASWNv7vmux6pH1LgTjWYEoRvdx9FUDws2dwvN3XL+h6OIrISrgpWY+g2+V9YC3wIrAY2OSR+TiwZ7zRugTnNwM92jbiJt0FfBeoD/Z7kHp1aODAC2Y228wmBcdS7XdrKFAJPBp06T1kZp1Jcj06QlJocQ2mNNCu62dmXYC/ADe6e1VLRZs41m7q4e517j6ayLftscDIpooFP9tdXczsPGCtu8+OPdxE0XZbh0ZOdPcxRLpUrjWzU1oo217rkgWMAe5z96OArezuKmpKm9SjIySF1tZgShVrzKwPQPBzbXC83dbPzLKJJIQ/uftfg8MpV49Y7r4JeI3IOEmRRZZzgT3jjdYlON8V2NC2ke7lROB8M1tGZBn7cURaDqlUhyh3rwh+rgX+RiRRp9rvVjlQ7u4Nz5J5hkiSSGo9OkJSmAUMC+6y6ARMBKYkOab9MQX4UrD9JSJ99A3H/yO4M+E4YHND0zOZzMyAh4GP3P1XMadSqh4AZlZiZkXBdh5wBpEBwVeBi4JijevSUMeLgFc86AROFne/xd37u/tgIv8GXnH3y0mhOjQws84WeTgXQXfLWcCHpNjvlruvBlaY2fDg0HhgPsmuR7IHW9poQOccIovzLQa+n+x44oj3CWAVsIvIt4OrifTnvgx8EvzsHpQ1IndXLQY+AEqTHX8Q10lEmrZzgfeD1zmpVo8gtiOA94K6fAjcGhwfCrwDLAImAznB8dxgf1Fwfmiy69CoPqcBz6VqHYKY5wSveQ3/plP0d2s0UBb8bv0d6JbsemhGs4iIRHWE7iMREYmTkoKIiEQpKYiISJSSgoiIRCkpiIhIlJKCtDtm9pqZfabRsRvN7LetXLcl5LhKghVD3zOzkxude83MSoPtwcEKl59p4j1+YZGVVn+xnzGc1rDCabD/v2Y2LVjV9LWGFUODc6UWefZ5w3VuZp+NOf+cmZ22P3FI+lJSkPboCSITrGJNDI4n03jgY3c/yt2nN1XAzPoTWUzuJnef1kSRa4Ax7v6deD4wZrZxU+e+T2Sm8ufcfWdwuKeZnd3MJeXA9+P5XOm4lBSkPXoGOM/MciC6oF5f4A0z62JmL5vZuxZZT/+Cxhc38W36HjO7Ktg+2sxeDxZSm9awnECj6wcFnzE3+DnQzEYDPwfOscga/nlNxN0beAH4gbvvNWvezKYAnYGZZnZJU58TlHvMzH5lZq/SzJLVZnYTkcmAn3X37TGnfgH8oKlriEz22mxmZzZzXkRJQdofd19PZBZtwzMlJgJPeWSm5Q7g8x5ZDO104P+CJTVaFazF9BvgInc/GngEuL2JovcAv3f3I4A/Ab929/eBW4M4Rjf6Q9zg98A97j65mXqdD2wPrn+qqc+JKX4IcIa739TEW50IfB04290bd5nNAHaa2elNxQD8L80nDRElBWm3YruQYruODPiJmc0FXiKydHCvON9zOHAY8KJFlsH+AZFFxRo7HvhzsP0HIkt2xOMl4Eozy4+zfEufM9nd65q5bhGR/w5nNXO+2T/8Dd1ejcdERBooKUh79XdgvEUeOZjn7u8Gxy8HSoCjPbKU9Roi6/TEqmXP3+2G8wbMC76pj3b3w929uT+sseJdC+bnRJ4ZMbmlsYA4P2drC+XWEOk6urOpFoG7v0Kkzsc1c/3taGxBmqGkIO1S0C3yGpEuntgB5q5EnguwK/iDOKiJy5cDo4I7croSGSCGyJOqSszseIh0J5nZoU1c/xa7WymXA2/sQ+jfAqqAh+Po1trvz3H3hcCFwB+D8Y7GbifyQJ2mrn2ByMJrR8b7edJxKClIe/YEkT9cT8Yc+xNQGtx6eTnwceOL3H0F8DSRlSf/RGSFU9y9hsgy0HeY2RwiK7ee0MTnXg98OeiiupLIc43jEox7fInIYxR/3krx/f6c4LNmAV8GppjZQY3OTSXyVK/m3E7TXWfSwWmVVBERiVJLQUREopQUREQkSklBRESilBRERCRKSUFERKKUFEREJEpJQUREopQUREQk6v8DgwwXZtHXypEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(k_range,scores_list)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_final = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_final.fit(df_x_scaled, df_y_converted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = DataFrame({'grade':[0,1.5,3.5,4.4,4.5],\n",
    "                   'activity':[1,3,3,4,4.5],\n",
    "                   'Coding':[0,1.5,2.9,3.9,4.5],\n",
    "                   'Teamwork':[0,1,2.9,3.8,4.5],\n",
    "                   'Math':[0,1,3.5,4.5,4.5]\n",
    "                   \n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>activity</th>\n",
       "      <th>Coding</th>\n",
       "      <th>Teamwork</th>\n",
       "      <th>Math</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.785459</td>\n",
       "      <td>-3.357978</td>\n",
       "      <td>-5.825491</td>\n",
       "      <td>-4.696438</td>\n",
       "      <td>-4.358580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.659681</td>\n",
       "      <td>-0.123766</td>\n",
       "      <td>-3.145111</td>\n",
       "      <td>-3.317991</td>\n",
       "      <td>-2.937528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.508024</td>\n",
       "      <td>-0.123766</td>\n",
       "      <td>-0.643423</td>\n",
       "      <td>-0.698941</td>\n",
       "      <td>0.615103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.383491</td>\n",
       "      <td>1.493340</td>\n",
       "      <td>1.143497</td>\n",
       "      <td>0.541661</td>\n",
       "      <td>2.036155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.591876</td>\n",
       "      <td>2.301893</td>\n",
       "      <td>2.215649</td>\n",
       "      <td>1.506574</td>\n",
       "      <td>2.036155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      grade  activity    Coding  Teamwork      Math\n",
       "0 -6.785459 -3.357978 -5.825491 -4.696438 -4.358580\n",
       "1 -3.659681 -0.123766 -3.145111 -3.317991 -2.937528\n",
       "2  0.508024 -0.123766 -0.643423 -0.698941  0.615103\n",
       "3  2.383491  1.493340  1.143497  0.541661  2.036155\n",
       "4  2.591876  2.301893  2.215649  1.506574  2.036155"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new_scaled = (x_new - df_x.mean())/df_x.std()\n",
    "x_new_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Dia\n",
      "Challenger\n"
     ]
    }
   ],
   "source": [
    "y_new_predict = knn_final.predict(x_new_scaled)\n",
    "\n",
    "for i in y_new_predict:\n",
    "    if i == 6 :\n",
    "        print('Bronze')\n",
    "    elif i == 1 :\n",
    "        print('Challenger')\n",
    "    elif i == 5 :\n",
    "        print('Silver')\n",
    "    elif i == 4 :\n",
    "        print('Gold')\n",
    "    elif i == 3 :\n",
    "        print('Platinum')\n",
    "    elif i == 2 :\n",
    "        print('Dia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../node/data/g.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = pd.read_excel('../node/data/first.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_subject = subject[subject['해당분야']=='수학']\n",
    "teample_subject = subject[subject['해당분야']=='팀플']\n",
    "coding_subject = subject[subject['해당분야']=='코딩개발']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "del math_subject['교과목번호']\n",
    "del teample_subject['교과목번호']\n",
    "del coding_subject['교과목번호']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.merge(df, math_subject, left_on = '교과목명', right_on = 'subject_name',  how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.merge(df_1,teample_subject, left_on = '교과목명', right_on = 'subject_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.merge(df_1,coding_subject, left_on = '교과목명', right_on = 'subject_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_1['subject_name_x']\n",
    "del df_1['subject_name_y']\n",
    "del df_1['subject_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_1.groupby(['class_number']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.merge(df_1, test['평점'],left_on = 'class_number', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_1.groupby(['class_number', '해당분야']).mean()\n",
    "df_1 = pd.merge(df_1, test['평점_x'],left_on = 'class_number', right_on='class_number', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_1.groupby(['class_number', '해당분야_x']).mean()\n",
    "df_1 = pd.merge(df_1, test['평점_x_x'],left_on = 'class_number', right_on='class_number', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_1.groupby(['class_number', '해당분야_y']).mean()\n",
    "df_1 = pd.merge(df_1, test['평점_x_x_x'],left_on = 'class_number', right_on='class_number', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_1['Unnamed: 0']\n",
    "del df_1['년도']\n",
    "del df_1['학기']\n",
    "del df_1['학번(입학연도)']\n",
    "del df_1['소속']\n",
    "del df_1['이수구분']\n",
    "del df_1['평가방식']\n",
    "del df_1['재수강']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.rename(columns={'평점_y':'grade'})\n",
    "df_1 = df_1.rename(columns={'평점_x_y':'Coding'})\n",
    "df_1 = df_1.rename(columns={'평점_x_x_y':'Math'})\n",
    "df_1 = df_1.rename(columns={'평점_x_x_x_y':'Teamwork'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_1['교과목번호']\n",
    "del df_1['교과목명']\n",
    "del df_1['교직영역']\n",
    "del df_1['선택영역']\n",
    "del df_1['학점']\n",
    "del df_1['등급']\n",
    "del df_1['평점_x_x_x_x']\n",
    "del df_1['해당분야_x']\n",
    "del df_1['해당분야_y']\n",
    "del df_1['해당분야']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.groupby('class_number').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['activity'] = df_1['grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Platinum\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Gold\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Challenger\n",
      "Gold\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Platinum\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Challenger\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Challenger\n",
      "Platinum\n",
      "Platinum\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Gold\n",
      "Dia\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Platinum\n",
      "Silver\n",
      "Silver\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Challenger\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Dia\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Gold\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Platinum\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Dia\n",
      "Gold\n",
      "Challenger\n",
      "Silver\n",
      "Platinum\n",
      "Platinum\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Gold\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Dia\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Gold\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Platinum\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Gold\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Gold\n",
      "Platinum\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Gold\n",
      "Silver\n",
      "Dia\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Platinum\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Platinum\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Challenger\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Platinum\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Dia\n",
      "Silver\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Silver\n",
      "Dia\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Dia\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Platinum\n",
      "Platinum\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Dia\n",
      "Gold\n",
      "Silver\n",
      "Silver\n",
      "Dia\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Gold\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Gold\n",
      "Gold\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Platinum\n",
      "Platinum\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Dia\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Platinum\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Dia\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Bronze\n",
      "Platinum\n",
      "Bronze\n",
      "Silver\n",
      "Platinum\n",
      "Bronze\n",
      "Gold\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n",
      "Silver\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Gold\n",
      "Bronze\n",
      "Bronze\n",
      "Bronze\n",
      "Silver\n"
     ]
    }
   ],
   "source": [
    "x_new = df_1\n",
    "x_new_scaled = (x_new - df_x.mean())/df_x.std()\n",
    "y_new_predict = knn_final.predict(x_new_scaled)\n",
    "k=0\n",
    "#df_1['등급'] = 'A'\n",
    "for i in y_new_predict:\n",
    "    if i == 6 :\n",
    "        print('Bronze')\n",
    "    elif i == 1 :\n",
    "        print('Challenger')\n",
    "    elif i == 5 :\n",
    "        print('Silver')\n",
    "    elif i == 4 :\n",
    "        print('Gold')\n",
    "    elif i == 3 :\n",
    "        print('Platinum')\n",
    "    elif i == 2 :\n",
    "        print('Dia')\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'등급' : y_new_predict}\n",
    "frame = DataFrame(data, index=df_1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.concat([df_1, frame], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_1.index :\n",
    "    if df_1.loc[i,'등급'] == 6 :\n",
    "        df_1.loc[i,'등급'] = 'Bronze'\n",
    "    elif df_1.loc[i,'등급'] == 5 :\n",
    "        df_1.loc[i,'등급'] = 'Silver'\n",
    "    elif df_1.loc[i,'등급'] == 4 :\n",
    "        df_1.loc[i,'등급'] = 'Gold'\n",
    "    elif df_1.loc[i,'등급'] == 3 :\n",
    "        df_1.loc[i,'등급'] = 'Platinum'\n",
    "    elif df_1.loc[i,'등급'] == 2 :\n",
    "        df_1.loc[i,'등급'] = 'Dia'\n",
    "    elif df_1.loc[i,'등급'] == 1 :\n",
    "        df_1.loc[i,'등급'] = 'Challenger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>Coding</th>\n",
       "      <th>Math</th>\n",
       "      <th>Teamwork</th>\n",
       "      <th>activity</th>\n",
       "      <th>등급</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s10</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s100</th>\n",
       "      <td>3.650000</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1000</th>\n",
       "      <td>3.026316</td>\n",
       "      <td>3.031250</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.026316</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1001</th>\n",
       "      <td>3.062500</td>\n",
       "      <td>3.041667</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.062500</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1002</th>\n",
       "      <td>2.416667</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1003</th>\n",
       "      <td>2.973684</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.973684</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1004</th>\n",
       "      <td>2.300000</td>\n",
       "      <td>2.041667</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1005</th>\n",
       "      <td>2.529412</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.529412</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1006</th>\n",
       "      <td>2.868421</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.868421</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1007</th>\n",
       "      <td>3.285714</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1008</th>\n",
       "      <td>2.366667</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.366667</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1009</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s101</th>\n",
       "      <td>2.850000</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1010</th>\n",
       "      <td>3.111111</td>\n",
       "      <td>3.307692</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1011</th>\n",
       "      <td>2.692308</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.692308</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1012</th>\n",
       "      <td>3.272727</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.272727</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1013</th>\n",
       "      <td>3.285714</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1014</th>\n",
       "      <td>3.550000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1015</th>\n",
       "      <td>3.708333</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.708333</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1016</th>\n",
       "      <td>1.916667</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1017</th>\n",
       "      <td>1.450000</td>\n",
       "      <td>1.441176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1018</th>\n",
       "      <td>2.357143</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1019</th>\n",
       "      <td>2.700000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s102</th>\n",
       "      <td>3.720000</td>\n",
       "      <td>3.775000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1020</th>\n",
       "      <td>3.416667</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1021</th>\n",
       "      <td>2.789474</td>\n",
       "      <td>2.781250</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.789474</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1022</th>\n",
       "      <td>3.269231</td>\n",
       "      <td>3.363636</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.269231</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1023</th>\n",
       "      <td>4.055556</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.055556</td>\n",
       "      <td>Platinum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1024</th>\n",
       "      <td>3.214286</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.214286</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s972</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s973</th>\n",
       "      <td>3.225000</td>\n",
       "      <td>3.281250</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.225000</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s974</th>\n",
       "      <td>3.416667</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s975</th>\n",
       "      <td>3.923077</td>\n",
       "      <td>4.023810</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.923077</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s976</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s977</th>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s978</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s979</th>\n",
       "      <td>2.437500</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s98</th>\n",
       "      <td>3.305556</td>\n",
       "      <td>3.294118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.305556</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s980</th>\n",
       "      <td>3.590909</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.590909</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s981</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s982</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Platinum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s983</th>\n",
       "      <td>2.277778</td>\n",
       "      <td>2.343750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>2.277778</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s984</th>\n",
       "      <td>3.125000</td>\n",
       "      <td>3.090909</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s985</th>\n",
       "      <td>3.823529</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.823529</td>\n",
       "      <td>Platinum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s986</th>\n",
       "      <td>2.676471</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s987</th>\n",
       "      <td>3.687500</td>\n",
       "      <td>3.642857</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s988</th>\n",
       "      <td>3.694444</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.694444</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s989</th>\n",
       "      <td>3.176471</td>\n",
       "      <td>3.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.176471</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s99</th>\n",
       "      <td>2.794118</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.794118</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s990</th>\n",
       "      <td>3.235294</td>\n",
       "      <td>3.035714</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.235294</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s991</th>\n",
       "      <td>3.062500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.062500</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s992</th>\n",
       "      <td>3.131579</td>\n",
       "      <td>3.093750</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.131579</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s993</th>\n",
       "      <td>2.777778</td>\n",
       "      <td>2.718750</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s994</th>\n",
       "      <td>3.117647</td>\n",
       "      <td>3.107143</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.117647</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s995</th>\n",
       "      <td>3.722222</td>\n",
       "      <td>3.785714</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.722222</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s996</th>\n",
       "      <td>2.558824</td>\n",
       "      <td>2.576923</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.558824</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s997</th>\n",
       "      <td>3.133333</td>\n",
       "      <td>3.230769</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s998</th>\n",
       "      <td>2.357143</td>\n",
       "      <td>2.264706</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s999</th>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2609 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 grade    Coding      Math  Teamwork  activity        등급\n",
       "class_number                                                            \n",
       "s1            3.600000  3.625000  3.500000  0.000000  3.600000    Silver\n",
       "s10           3.500000  3.500000  0.000000  3.500000  3.500000    Bronze\n",
       "s100          3.650000  3.593750  3.666667  4.500000  3.650000      Gold\n",
       "s1000         3.026316  3.031250  3.000000  2.500000  3.026316    Silver\n",
       "s1001         3.062500  3.041667  2.500000  3.000000  3.062500    Bronze\n",
       "s1002         2.416667  2.250000  2.500000  3.333333  2.416667    Bronze\n",
       "s1003         2.973684  3.000000  2.500000  3.000000  2.973684    Bronze\n",
       "s1004         2.300000  2.041667  2.500000  3.500000  2.300000    Bronze\n",
       "s1005         2.529412  2.500000  3.250000  0.000000  2.529412    Bronze\n",
       "s1006         2.868421  3.000000  3.250000  3.000000  2.868421    Silver\n",
       "s1007         3.285714  3.600000  2.000000  3.000000  3.285714    Bronze\n",
       "s1008         2.366667  2.363636  0.000000  3.500000  2.366667    Bronze\n",
       "s1009         2.500000  2.500000  0.000000  2.500000  2.500000    Bronze\n",
       "s101          2.850000  2.777778  3.000000  4.000000  2.850000    Silver\n",
       "s1010         3.111111  3.307692  2.000000  4.500000  3.111111    Bronze\n",
       "s1011         2.692308  2.636364  2.500000  3.500000  2.692308    Bronze\n",
       "s1012         3.272727  3.312500  2.500000  4.500000  3.272727    Silver\n",
       "s1013         3.285714  3.285714  2.875000  4.500000  3.285714    Silver\n",
       "s1014         3.550000  3.666667  0.000000  2.500000  3.550000    Bronze\n",
       "s1015         3.708333  3.600000  4.000000  4.500000  3.708333      Gold\n",
       "s1016         1.916667  1.700000  0.000000  3.000000  1.916667    Bronze\n",
       "s1017         1.450000  1.441176  1.000000  2.500000  1.450000    Bronze\n",
       "s1018         2.357143  2.166667  0.000000  3.500000  2.357143    Bronze\n",
       "s1019         2.700000  2.500000  0.000000  3.500000  2.700000    Bronze\n",
       "s102          3.720000  3.775000  3.500000  3.000000  3.720000    Silver\n",
       "s1020         3.416667  3.566667  2.250000  3.500000  3.416667    Bronze\n",
       "s1021         2.789474  2.781250  2.500000  3.500000  2.789474    Bronze\n",
       "s1022         3.269231  3.363636  2.000000  3.500000  3.269231    Bronze\n",
       "s1023         4.055556  3.928571  4.500000  4.500000  4.055556  Platinum\n",
       "s1024         3.214286  3.300000  2.500000  3.500000  3.214286    Bronze\n",
       "...                ...       ...       ...       ...       ...       ...\n",
       "s972          0.000000  0.000000  0.000000  0.000000  0.000000    Bronze\n",
       "s973          3.225000  3.281250  3.500000  2.500000  3.225000    Silver\n",
       "s974          3.416667  3.200000  4.500000  0.000000  3.416667    Silver\n",
       "s975          3.923077  4.023810  4.250000  0.000000  3.923077    Silver\n",
       "s976          3.500000  3.500000  3.500000  0.000000  3.500000    Silver\n",
       "s977          3.200000  3.166667  3.500000  0.000000  3.200000    Bronze\n",
       "s978          3.900000  4.000000  3.500000  3.500000  3.900000      Gold\n",
       "s979          2.437500  2.214286  0.000000  4.000000  2.437500    Bronze\n",
       "s98           3.305556  3.294118  0.000000  3.500000  3.305556    Bronze\n",
       "s980          3.590909  3.375000  4.500000  3.500000  3.590909    Silver\n",
       "s981          3.666667  3.687500  0.000000  3.500000  3.666667    Bronze\n",
       "s982          4.000000  3.666667  4.500000  4.500000  4.000000  Platinum\n",
       "s983          2.277778  2.343750  1.000000  1.750000  2.277778    Bronze\n",
       "s984          3.125000  3.090909  3.125000  3.500000  3.125000    Silver\n",
       "s985          3.823529  3.769231  3.833333  4.500000  3.823529  Platinum\n",
       "s986          2.676471  2.187500  2.000000  4.500000  2.676471    Bronze\n",
       "s987          3.687500  3.642857  3.500000  4.500000  3.687500      Gold\n",
       "s988          3.694444  3.750000  3.500000  3.500000  3.694444      Gold\n",
       "s989          3.176471  3.176471  0.000000  0.000000  3.176471    Bronze\n",
       "s99           2.794118  2.750000  2.500000  4.000000  2.794118    Bronze\n",
       "s990          3.235294  3.035714  3.500000  4.500000  3.235294    Silver\n",
       "s991          3.062500  3.000000  3.500000  3.500000  3.062500    Silver\n",
       "s992          3.131579  3.093750  3.250000  0.000000  3.131579    Bronze\n",
       "s993          2.777778  2.718750  2.000000  4.500000  2.777778    Bronze\n",
       "s994          3.117647  3.107143  3.166667  0.000000  3.117647    Bronze\n",
       "s995          3.722222  3.785714  3.166667  4.500000  3.722222      Gold\n",
       "s996          2.558824  2.576923  2.166667  3.500000  2.558824    Bronze\n",
       "s997          3.133333  3.230769  2.500000  0.000000  3.133333    Bronze\n",
       "s998          2.357143  2.264706  2.500000  3.000000  2.357143    Bronze\n",
       "s999          3.250000  3.250000  3.166667  3.500000  3.250000    Silver\n",
       "\n",
       "[2609 rows x 6 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv(r\"../node/data/등급분류완료.csv\", header = True, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df[['class_number', '소속']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_number = a.drop_duplicates(['class_number'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_number</th>\n",
       "      <th>소속</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15449</th>\n",
       "      <td>s1</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class_number               소속\n",
       "15449           s1  전자정보공학대학 컴퓨터공학과"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_number[class_number['class_number']=='s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "depart = a.drop_duplicates(['소속'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "depart[\"departID\"] = depart[\"소속\"].apply(lambda x: 1 if x == '전자정보공학대학 디지털콘텐츠학과' else 2 if x ==  '전자정보공학대학 컴퓨터공학과'\n",
    "                                    else 3 if x == '전자정보공학대학 정보보호학과'\n",
    "                                    else 4 if x == '소프트웨어융합대학 컴퓨터공학과'\n",
    "                                    else 5 if x == \"소프트웨어융합대학 정보보호학과\"\n",
    "                                    else 6 if x == '소프트웨어융합대학 소프트웨어학과'\n",
    "                                    else 7 if x == '소프트웨어융합대학 데이터사이언스학과'\n",
    "                                    else 8 if x == '소프트웨어융합대학 지능기전공학부'\n",
    "                                    else 9 if x == '소프트웨어융합대학 지능기전공학부 무인이동체공학전공'\n",
    "                                    else 10 if x == '소프트웨어융합대학 지능기전공학부 스마트기기공학전공'\n",
    "                                    else 11 if x == '소프트웨어융합대학 창의소프트학부'\n",
    "                                    else 12 if x == '소프트웨어융합대학 창의소프트학부 디자인이노베이션전공'\n",
    "                                    else 13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_number</th>\n",
       "      <th>소속</th>\n",
       "      <th>departID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15444</th>\n",
       "      <td>s1668</td>\n",
       "      <td>전자정보공학대학 디지털콘텐츠학과</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18946</th>\n",
       "      <td>s1657</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19521</th>\n",
       "      <td>s1659</td>\n",
       "      <td>전자정보공학대학 정보보호학과</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20250</th>\n",
       "      <td>s2724</td>\n",
       "      <td>소프트웨어융합대학 컴퓨터공학과</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20477</th>\n",
       "      <td>s2699</td>\n",
       "      <td>소프트웨어융합대학 정보보호학과</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20783</th>\n",
       "      <td>s2701</td>\n",
       "      <td>소프트웨어융합대학 소프트웨어학과</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20983</th>\n",
       "      <td>s2450</td>\n",
       "      <td>소프트웨어융합대학 데이터사이언스학과</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21085</th>\n",
       "      <td>s2702</td>\n",
       "      <td>소프트웨어융합대학 지능기전공학부</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21378</th>\n",
       "      <td>s2052</td>\n",
       "      <td>소프트웨어융합대학 지능기전공학부 무인이동체공학전공</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21715</th>\n",
       "      <td>s2054</td>\n",
       "      <td>소프트웨어융합대학 지능기전공학부 스마트기기공학전공</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22086</th>\n",
       "      <td>s2718</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22414</th>\n",
       "      <td>s2102</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 디자인이노베이션전공</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22800</th>\n",
       "      <td>s2166</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class_number                            소속  departID\n",
       "15444        s1668             전자정보공학대학 디지털콘텐츠학과         1\n",
       "18946        s1657               전자정보공학대학 컴퓨터공학과         2\n",
       "19521        s1659               전자정보공학대학 정보보호학과         3\n",
       "20250        s2724              소프트웨어융합대학 컴퓨터공학과         4\n",
       "20477        s2699              소프트웨어융합대학 정보보호학과         5\n",
       "20783        s2701             소프트웨어융합대학 소프트웨어학과         6\n",
       "20983        s2450           소프트웨어융합대학 데이터사이언스학과         7\n",
       "21085        s2702             소프트웨어융합대학 지능기전공학부         8\n",
       "21378        s2052   소프트웨어융합대학 지능기전공학부 무인이동체공학전공         9\n",
       "21715        s2054   소프트웨어융합대학 지능기전공학부 스마트기기공학전공        10\n",
       "22086        s2718             소프트웨어융합대학 창의소프트학부        11\n",
       "22414        s2102  소프트웨어융합대학 창의소프트학부 디자인이노베이션전공        12\n",
       "22800        s2166  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공        13"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_number = pd.merge(class_number, depart, left_on = '소속', right_on = '소속',  how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_number['departID'] = class_number['departID'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pymysql 설치해야함\n",
    "import pymysql\n",
    "\n",
    "# 데이터 베이스에 접속하는 함수\n",
    "def get_connection() :\n",
    "    conn = pymysql.connect(host='127.0.0.1', user='root',\n",
    "            password='6301tkrhk!@', db='capstone', charset='utf8')\n",
    "\n",
    "    return conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 사용자 정보를 저장하는 함수\n",
    "def add_user(studentID, name, password, departID, email, auth) :\n",
    "    # 쿼리문\n",
    "    sql = '''insert into user\n",
    "             (studentID, name, password, departID, email, auth) values (%s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "    # 접속\n",
    "    conn = get_connection()\n",
    "    # 쿼리실행\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql, (studentID, name, password, departID, email, auth))\n",
    "\n",
    "    # 접속해제\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "get_connection()\n",
    "k=0\n",
    "for i in class_number.index :\n",
    "    a = class_number['departID'][k]\n",
    "    a = int(a)\n",
    "    add_user(k, class_number['class_number_x'][k], '1234', a, 'capstone', False )\n",
    "    k= k+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_number['studentID'] = class_number.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_number_x</th>\n",
       "      <th>소속</th>\n",
       "      <th>class_number_y</th>\n",
       "      <th>departID</th>\n",
       "      <th>studentID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s63</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s64</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s66</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s72</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s74</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s76</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s78</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s80</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s81</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s82</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>s83</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>s85</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>s87</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>s92</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>s93</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>s99</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>s102</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>s108</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s109</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>s112</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>s117</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>s119</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>s124</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>s126</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>s127</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>s134</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>s135</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>s136</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>s143</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>s146</td>\n",
       "      <td>전자정보공학대학 컴퓨터공학과</td>\n",
       "      <td>s1657</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>s2124</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>s2125</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>s2126</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>s2127</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>s2128</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>s2129</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>s2130</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>s2131</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>s2132</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>s2133</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>s2134</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>s2135</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>s2136</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>s2137</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>s2138</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>s2139</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>s2140</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>s2141</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>s2142</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>s2143</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>s2144</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>s2145</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>s2146</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>s2147</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>s2148</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>s2149</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>s2150</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>s2151</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>s2165</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>s2166</td>\n",
       "      <td>소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공</td>\n",
       "      <td>s2166</td>\n",
       "      <td>13</td>\n",
       "      <td>2608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2609 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class_number_x                            소속 class_number_y  departID  \\\n",
       "0               s63               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "1               s64               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "2               s66               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "3               s72               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "4               s74               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "5               s76               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "6               s78               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "7               s80               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "8               s81               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "9               s82               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "10              s83               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "11              s85               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "12              s87               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "13              s92               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "14              s93               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "15              s99               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "16             s102               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "17             s108               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "18             s109               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "19             s112               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "20             s117               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "21             s119               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "22             s124               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "23             s126               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "24             s127               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "25             s134               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "26             s135               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "27             s136               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "28             s143               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "29             s146               전자정보공학대학 컴퓨터공학과          s1657         2   \n",
       "...             ...                           ...            ...       ...   \n",
       "2579          s2124  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2580          s2125  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2581          s2126  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2582          s2127  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2583          s2128  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2584          s2129  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2585          s2130  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2586          s2131  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2587          s2132  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2588          s2133  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2589          s2134  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2590          s2135  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2591          s2136  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2592          s2137  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2593          s2138  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2594          s2139  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2595          s2140  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2596          s2141  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2597          s2142  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2598          s2143  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2599          s2144  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2600          s2145  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2601          s2146  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2602          s2147  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2603          s2148  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2604          s2149  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2605          s2150  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2606          s2151  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2607          s2165  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "2608          s2166  소프트웨어융합대학 창의소프트학부 만화애니메이션텍전공          s2166        13   \n",
       "\n",
       "      studentID  \n",
       "0             0  \n",
       "1             1  \n",
       "2             2  \n",
       "3             3  \n",
       "4             4  \n",
       "5             5  \n",
       "6             6  \n",
       "7             7  \n",
       "8             8  \n",
       "9             9  \n",
       "10           10  \n",
       "11           11  \n",
       "12           12  \n",
       "13           13  \n",
       "14           14  \n",
       "15           15  \n",
       "16           16  \n",
       "17           17  \n",
       "18           18  \n",
       "19           19  \n",
       "20           20  \n",
       "21           21  \n",
       "22           22  \n",
       "23           23  \n",
       "24           24  \n",
       "25           25  \n",
       "26           26  \n",
       "27           27  \n",
       "28           28  \n",
       "29           29  \n",
       "...         ...  \n",
       "2579       2579  \n",
       "2580       2580  \n",
       "2581       2581  \n",
       "2582       2582  \n",
       "2583       2583  \n",
       "2584       2584  \n",
       "2585       2585  \n",
       "2586       2586  \n",
       "2587       2587  \n",
       "2588       2588  \n",
       "2589       2589  \n",
       "2590       2590  \n",
       "2591       2591  \n",
       "2592       2592  \n",
       "2593       2593  \n",
       "2594       2594  \n",
       "2595       2595  \n",
       "2596       2596  \n",
       "2597       2597  \n",
       "2598       2598  \n",
       "2599       2599  \n",
       "2600       2600  \n",
       "2601       2601  \n",
       "2602       2602  \n",
       "2603       2603  \n",
       "2604       2604  \n",
       "2605       2605  \n",
       "2606       2606  \n",
       "2607       2607  \n",
       "2608       2608  \n",
       "\n",
       "[2609 rows x 5 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(class_number['class_number_x']track = pd.read_excel('../node/data/track.xlsx')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(class_number['departID'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = pd.read_excel('C:/Users/User/Desktop/capstone_4/node/data/first.xlsx')\n",
    "track = pd.read_excel('../node/data/track.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_1 = pd.merge(subject, track, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>교과목번호</th>\n",
       "      <th>subject_name</th>\n",
       "      <th>해당분야</th>\n",
       "      <th>trackID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2647</td>\n",
       "      <td>일반물리학및실험1</td>\n",
       "      <td>수학</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4109</td>\n",
       "      <td>프로그래밍1</td>\n",
       "      <td>코딩개발</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6279</td>\n",
       "      <td>정보사회의사이버윤리</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7323</td>\n",
       "      <td>쓰기와말하기</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7325</td>\n",
       "      <td>미적분학및연습1</td>\n",
       "      <td>수학</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8303</td>\n",
       "      <td>English Composition 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8360</td>\n",
       "      <td>신입생세미나1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2649</td>\n",
       "      <td>일반물리학및실험2</td>\n",
       "      <td>수학</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2703</td>\n",
       "      <td>일반화학</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3437</td>\n",
       "      <td>프로그래밍2</td>\n",
       "      <td>코딩개발</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3435</td>\n",
       "      <td>프로그래밍2</td>\n",
       "      <td>코딩개발</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4794</td>\n",
       "      <td>채플4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7326</td>\n",
       "      <td>미적분학및연습2</td>\n",
       "      <td>수학</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8304</td>\n",
       "      <td>English Composition 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8381</td>\n",
       "      <td>세종리더십</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9068</td>\n",
       "      <td>서양철학:쟁점과토론</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>304</td>\n",
       "      <td>공업수학1</td>\n",
       "      <td>수학</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4114</td>\n",
       "      <td>전기회로</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4272</td>\n",
       "      <td>물리전자공학</td>\n",
       "      <td>수학</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4111</td>\n",
       "      <td>물리전자공학</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4777</td>\n",
       "      <td>채플3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5611</td>\n",
       "      <td>디지털논리회로</td>\n",
       "      <td>코딩개발</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7452</td>\n",
       "      <td>전자공학기초설계1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9065</td>\n",
       "      <td>English Writing 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1725</td>\n",
       "      <td>선형대수</td>\n",
       "      <td>수학</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2010</td>\n",
       "      <td>알고리즘</td>\n",
       "      <td>코딩개발</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>F02974</td>\n",
       "      <td>알고리즘</td>\n",
       "      <td>코딩개발</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2493</td>\n",
       "      <td>이산수학</td>\n",
       "      <td>수학</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3276</td>\n",
       "      <td>컴퓨터구조론</td>\n",
       "      <td>코딩개발</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3284</td>\n",
       "      <td>컴퓨터네트워크</td>\n",
       "      <td>코딩개발</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>NaN</td>\n",
       "      <td>고급실시간그래픽스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>NaN</td>\n",
       "      <td>고급실시간그래픽스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>NaN</td>\n",
       "      <td>고급실시간그래픽스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>NaN</td>\n",
       "      <td>고급실시간그래픽스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>NaN</td>\n",
       "      <td>고급실시간그래픽스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>NaN</td>\n",
       "      <td>고급실시간그래픽스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>NaN</td>\n",
       "      <td>고급실시간그래픽스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>NaN</td>\n",
       "      <td>고급실시간그래픽스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>NaN</td>\n",
       "      <td>고급실시간그래픽스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>NaN</td>\n",
       "      <td>고급실시간그래픽스</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>NaN</td>\n",
       "      <td>시스템해킹과보안</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>NaN</td>\n",
       "      <td>시스템해킹과보안</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>NaN</td>\n",
       "      <td>시스템해킹과보안</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>NaN</td>\n",
       "      <td>시스템해킹과보안</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>NaN</td>\n",
       "      <td>시스템해킹과보안</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>NaN</td>\n",
       "      <td>시스템해킹과보안</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>NaN</td>\n",
       "      <td>시스템해킹과보안</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>NaN</td>\n",
       "      <td>시스템해킹과보안</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>NaN</td>\n",
       "      <td>시스템해킹과보안</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>NaN</td>\n",
       "      <td>시스템해킹과보안</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>NaN</td>\n",
       "      <td>컴퓨터애니메이션</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>NaN</td>\n",
       "      <td>컴퓨터애니메이션</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>NaN</td>\n",
       "      <td>컴퓨터애니메이션</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>NaN</td>\n",
       "      <td>컴퓨터애니메이션</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>NaN</td>\n",
       "      <td>컴퓨터애니메이션</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>NaN</td>\n",
       "      <td>컴퓨터애니메이션</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>NaN</td>\n",
       "      <td>컴퓨터애니메이션</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>NaN</td>\n",
       "      <td>컴퓨터애니메이션</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>NaN</td>\n",
       "      <td>컴퓨터애니메이션</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>NaN</td>\n",
       "      <td>컴퓨터애니메이션</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1759 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       교과목번호           subject_name  해당분야  trackID\n",
       "0       2647              일반물리학및실험1    수학      NaN\n",
       "1       4109                 프로그래밍1  코딩개발      NaN\n",
       "2       6279             정보사회의사이버윤리   NaN      NaN\n",
       "3       7323                 쓰기와말하기   NaN      NaN\n",
       "4       7325               미적분학및연습1    수학      NaN\n",
       "5       8303  English Composition 1   NaN      NaN\n",
       "6       8360                신입생세미나1   NaN      NaN\n",
       "7       2649              일반물리학및실험2    수학      NaN\n",
       "8       2703                   일반화학   NaN      NaN\n",
       "9       3437                 프로그래밍2  코딩개발      NaN\n",
       "10      3435                 프로그래밍2  코딩개발      NaN\n",
       "11      4794                    채플4   NaN      NaN\n",
       "12      7326               미적분학및연습2    수학      NaN\n",
       "13      8304  English Composition 2   NaN      NaN\n",
       "14      8381                  세종리더십   NaN      NaN\n",
       "15      9068             서양철학:쟁점과토론   NaN      NaN\n",
       "16       304                  공업수학1    수학      NaN\n",
       "17      4114                   전기회로   NaN      NaN\n",
       "18      4272                 물리전자공학    수학      NaN\n",
       "19      4111                 물리전자공학   NaN      NaN\n",
       "20      4777                    채플3   NaN      NaN\n",
       "21      5611                디지털논리회로  코딩개발      NaN\n",
       "22      7452              전자공학기초설계1   NaN      NaN\n",
       "23      9065      English Writing 1   NaN      NaN\n",
       "24      1725                   선형대수    수학      NaN\n",
       "25      2010                   알고리즘  코딩개발      NaN\n",
       "26    F02974                   알고리즘  코딩개발      NaN\n",
       "27      2493                   이산수학    수학      NaN\n",
       "28      3276                 컴퓨터구조론  코딩개발      NaN\n",
       "29      3284                컴퓨터네트워크  코딩개발      1.0\n",
       "...      ...                    ...   ...      ...\n",
       "1729     NaN              고급실시간그래픽스   NaN      1.0\n",
       "1730     NaN              고급실시간그래픽스   NaN      2.0\n",
       "1731     NaN              고급실시간그래픽스   NaN      3.0\n",
       "1732     NaN              고급실시간그래픽스   NaN      4.0\n",
       "1733     NaN              고급실시간그래픽스   NaN      5.0\n",
       "1734     NaN              고급실시간그래픽스   NaN      6.0\n",
       "1735     NaN              고급실시간그래픽스   NaN      7.0\n",
       "1736     NaN              고급실시간그래픽스   NaN      8.0\n",
       "1737     NaN              고급실시간그래픽스   NaN      9.0\n",
       "1738     NaN              고급실시간그래픽스   NaN     10.0\n",
       "1739     NaN               시스템해킹과보안   NaN      1.0\n",
       "1740     NaN               시스템해킹과보안   NaN      2.0\n",
       "1741     NaN               시스템해킹과보안   NaN      3.0\n",
       "1742     NaN               시스템해킹과보안   NaN      4.0\n",
       "1743     NaN               시스템해킹과보안   NaN      5.0\n",
       "1744     NaN               시스템해킹과보안   NaN      6.0\n",
       "1745     NaN               시스템해킹과보안   NaN      7.0\n",
       "1746     NaN               시스템해킹과보안   NaN      8.0\n",
       "1747     NaN               시스템해킹과보안   NaN      9.0\n",
       "1748     NaN               시스템해킹과보안   NaN     10.0\n",
       "1749     NaN               컴퓨터애니메이션   NaN      1.0\n",
       "1750     NaN               컴퓨터애니메이션   NaN      2.0\n",
       "1751     NaN               컴퓨터애니메이션   NaN      3.0\n",
       "1752     NaN               컴퓨터애니메이션   NaN      4.0\n",
       "1753     NaN               컴퓨터애니메이션   NaN      5.0\n",
       "1754     NaN               컴퓨터애니메이션   NaN      6.0\n",
       "1755     NaN               컴퓨터애니메이션   NaN      7.0\n",
       "1756     NaN               컴퓨터애니메이션   NaN      8.0\n",
       "1757     NaN               컴퓨터애니메이션   NaN      9.0\n",
       "1758     NaN               컴퓨터애니메이션   NaN     10.0\n",
       "\n",
       "[1759 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject[\"해당분야\"] = subject[\"해당분야\"].apply(lambda x: 1 if x == '코딩개발' else 2 if x ==  '수학'\n",
    "                                    else 3 if x == '팀플'\n",
    "                                    else 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymysql.connections.Connection at 0x21e2d77ab00>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "subject = pd.read_excel('../node/data/first.xlsx')\n",
    "track = pd.read_excel('../node/data/track.xlsx')\n",
    "\n",
    "track_1 = pd.merge(subject, track, how='outer')\n",
    "\n",
    "subject[\"해당분야\"] = subject[\"해당분야\"].apply(lambda x: 1 if x == '코딩개발' else 2 if x ==  '수학'\n",
    "                                    else 3 if x == '팀플'\n",
    "                                    else 4)\n",
    "\n",
    "def add_subject(subjectnumber, name, trackID) :\n",
    "    # 쿼리문\n",
    "    sql = '''insert into subject\n",
    "             (subjectnumber, name, trackID) values (%s, %s, %s)'''\n",
    "\n",
    "    # 접속\n",
    "    conn = get_connection()\n",
    "    # 쿼리실행\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql, (subjectnumber, name, trackID))\n",
    "\n",
    "    # 접속해제\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "get_connection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_1['trackID'] = track_1['trackID'].fillna(0)\n",
    "track_1['교과목번호'] = track_1['교과목번호'].fillna(-1) \n",
    "for i in track_1.index :\n",
    "    a = track_1['trackID'][i]\n",
    "    a = int(a)\n",
    "    add_subject(track_1['교과목번호'][i], track_1['subject_name'][i], a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_track(id, name, track_explain) :\n",
    "    # 쿼리문\n",
    "    sql = '''insert into track\n",
    "             (id, name, track_explain) values (%s, %s, %s)'''\n",
    "\n",
    "    # 접속\n",
    "    conn = get_connection()\n",
    "    # 쿼리실행\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql, (id, name, track_explain))\n",
    "\n",
    "    # 접속해제\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "get_connection()\n",
    "\n",
    "add_track(1, '시스템응용', '시스템응용')\n",
    "add_track(2, '멀티미디어', '멀티미디어')\n",
    "add_track(3, '사물인터넷', '사물인터넷')\n",
    "add_track(4, '인공지능', '인공지능')\n",
    "add_track(5, '가상현실', '가상현실')\n",
    "add_track(6, 'SW교육', 'SW교육')\n",
    "add_track(7, '정보보호', '정보보호')\n",
    "add_track(8, '데이터사이언스', '데이터사이언스')\n",
    "add_track(9, '사이버국방', '사이버국방')\n",
    "add_track(10, 'HCI&비쥬얼컴퓨팅', 'HCI&비쥬얼컴퓨팅')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../node/data/g.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_student_track() :\n",
    "    # 쿼리문\n",
    "    sql = '''insert into student_track\n",
    "             (studentID, trackID, track_score)\n",
    "             select x.studentID, y.trackID, avg(x.score)\n",
    "             from score x, subject y\n",
    "             where x.majorid = y.id\n",
    "             group by x.studentID, y.trackID;'''\n",
    "\n",
    "    # 접속\n",
    "    conn = get_connection()\n",
    "    # 쿼리실행\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql, ())\n",
    "\n",
    "    # 접속해제\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "add_student_track()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>교과목번호</th>\n",
       "      <th>subject_name</th>\n",
       "      <th>해당분야</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2647</td>\n",
       "      <td>일반물리학및실험1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4109</td>\n",
       "      <td>프로그래밍1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6279</td>\n",
       "      <td>정보사회의사이버윤리</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7323</td>\n",
       "      <td>쓰기와말하기</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7325</td>\n",
       "      <td>미적분학및연습1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8303</td>\n",
       "      <td>English Composition 1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8360</td>\n",
       "      <td>신입생세미나1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2649</td>\n",
       "      <td>일반물리학및실험2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2703</td>\n",
       "      <td>일반화학</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3437</td>\n",
       "      <td>프로그래밍2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4794</td>\n",
       "      <td>채플4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7326</td>\n",
       "      <td>미적분학및연습2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8304</td>\n",
       "      <td>English Composition 2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8381</td>\n",
       "      <td>세종리더십</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9068</td>\n",
       "      <td>서양철학:쟁점과토론</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>304</td>\n",
       "      <td>공업수학1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4114</td>\n",
       "      <td>전기회로</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4272</td>\n",
       "      <td>물리전자공학</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4777</td>\n",
       "      <td>채플3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5611</td>\n",
       "      <td>디지털논리회로</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7452</td>\n",
       "      <td>전자공학기초설계1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9065</td>\n",
       "      <td>English Writing 1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1725</td>\n",
       "      <td>선형대수</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2010</td>\n",
       "      <td>알고리즘</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2493</td>\n",
       "      <td>이산수학</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3276</td>\n",
       "      <td>컴퓨터구조론</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3284</td>\n",
       "      <td>컴퓨터네트워크</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8364</td>\n",
       "      <td>세종사회봉사1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8377</td>\n",
       "      <td>전산개론-I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9066</td>\n",
       "      <td>English Writing 2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>010369</td>\n",
       "      <td>일본어A2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>010277</td>\n",
       "      <td>디지털드로잉</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>010278</td>\n",
       "      <td>창의융합노마드(P/NP)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>005119</td>\n",
       "      <td>만화기초1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>006205</td>\n",
       "      <td>해부학</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>010274</td>\n",
       "      <td>라이프드로잉</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>010279</td>\n",
       "      <td>내러티브워크샵</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>010280</td>\n",
       "      <td>만화제작</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>010307</td>\n",
       "      <td>3D디자인</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>008785</td>\n",
       "      <td>애니메이션기초1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>008659</td>\n",
       "      <td>서양미술사1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>010275</td>\n",
       "      <td>비쥬얼씽킹</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>010531</td>\n",
       "      <td>세계시민정신</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>001030</td>\n",
       "      <td>디자인사</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>010309</td>\n",
       "      <td>프로덕트디자인1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>010311</td>\n",
       "      <td>비주얼커뮤니케이션디자인1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>010310</td>\n",
       "      <td>프로덕트디자인2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>006225</td>\n",
       "      <td>기초렌더링</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>004468</td>\n",
       "      <td>패션일러스트레이션</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>007034</td>\n",
       "      <td>무대매커니즘1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>004744</td>\n",
       "      <td>모델드로잉</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>009614</td>\n",
       "      <td>호텔관광마케팅</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>009888</td>\n",
       "      <td>축제경영연구</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>005253</td>\n",
       "      <td>만화기초2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>008786</td>\n",
       "      <td>애니메이션기초2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>008218</td>\n",
       "      <td>컨셉디자인</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>008790</td>\n",
       "      <td>콘텐츠기획1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>010281</td>\n",
       "      <td>애니메이션액팅1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>009508</td>\n",
       "      <td>자바프로그래밍</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>010500</td>\n",
       "      <td>모델링&amp;텍스처링</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1196 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       교과목번호           subject_name  해당분야\n",
       "0       2647              일반물리학및실험1     2\n",
       "1       4109                 프로그래밍1     1\n",
       "2       6279             정보사회의사이버윤리     4\n",
       "3       7323                 쓰기와말하기     4\n",
       "4       7325               미적분학및연습1     2\n",
       "5       8303  English Composition 1     4\n",
       "6       8360                신입생세미나1     4\n",
       "7       2649              일반물리학및실험2     2\n",
       "8       2703                   일반화학     4\n",
       "9       3437                 프로그래밍2     1\n",
       "10      4794                    채플4     4\n",
       "11      7326               미적분학및연습2     2\n",
       "12      8304  English Composition 2     4\n",
       "13      8381                  세종리더십     4\n",
       "14      9068             서양철학:쟁점과토론     4\n",
       "15       304                  공업수학1     2\n",
       "16      4114                   전기회로     4\n",
       "17      4272                 물리전자공학     2\n",
       "18      4777                    채플3     4\n",
       "19      5611                디지털논리회로     1\n",
       "20      7452              전자공학기초설계1     4\n",
       "21      9065      English Writing 1     4\n",
       "22      1725                   선형대수     2\n",
       "23      2010                   알고리즘     1\n",
       "24      2493                   이산수학     2\n",
       "25      3276                 컴퓨터구조론     1\n",
       "26      3284                컴퓨터네트워크     1\n",
       "27      8364                세종사회봉사1     4\n",
       "28      8377                 전산개론-I     1\n",
       "29      9066      English Writing 2     4\n",
       "...      ...                    ...   ...\n",
       "1166  010369                  일본어A2     4\n",
       "1167  010277                 디지털드로잉     4\n",
       "1168  010278          창의융합노마드(P/NP)     4\n",
       "1169  005119                  만화기초1     4\n",
       "1170  006205                    해부학     4\n",
       "1171  010274                 라이프드로잉     4\n",
       "1172  010279                내러티브워크샵     4\n",
       "1173  010280                   만화제작     4\n",
       "1174  010307                  3D디자인     4\n",
       "1175  008785               애니메이션기초1     4\n",
       "1176  008659                 서양미술사1     4\n",
       "1177  010275                  비쥬얼씽킹     4\n",
       "1178  010531                 세계시민정신     4\n",
       "1179  001030                   디자인사     4\n",
       "1180  010309               프로덕트디자인1     4\n",
       "1181  010311          비주얼커뮤니케이션디자인1     4\n",
       "1182  010310               프로덕트디자인2     4\n",
       "1183  006225                  기초렌더링     4\n",
       "1184  004468              패션일러스트레이션     4\n",
       "1185  007034                무대매커니즘1     4\n",
       "1186  004744                  모델드로잉     4\n",
       "1187  009614                호텔관광마케팅     4\n",
       "1188  009888                 축제경영연구     4\n",
       "1189  005253                  만화기초2     4\n",
       "1190  008786               애니메이션기초2     4\n",
       "1191  008218                  컨셉디자인     4\n",
       "1192  008790                 콘텐츠기획1     4\n",
       "1193  010281               애니메이션액팅1     4\n",
       "1194  009508                자바프로그래밍     1\n",
       "1195  010500               모델링&텍스처링     1\n",
       "\n",
       "[1196 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = subject[subject['subject_name']==df['교과목명'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = int(b[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'translate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-6e445ca95778>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0madd_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'평점'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'등급'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-57-6e445ca95778>\u001b[0m in \u001b[0;36madd_score\u001b[1;34m(studnetID, majorid, score, grade)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# 쿼리실행\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstudnetID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmajorid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrade\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# 접속해제\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmogrify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36mmogrify\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m             \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_escape_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36m_escape_args\u001b[1;34m(self, args, conn)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliteral\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliteral\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mliteral\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mNon\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstandard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minternal\u001b[0m \u001b[0muse\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mdo\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0muse\u001b[0m \u001b[0mthis\u001b[0m \u001b[1;32min\u001b[0m \u001b[0myour\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \"\"\"\n\u001b[1;32m--> 467\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mescape_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mescape\u001b[1;34m(self, obj, mapping)\u001b[0m\n\u001b[0;32m    458\u001b[0m                 \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"_binary\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconverters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mescape_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mliteral\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pymysql\\converters.py\u001b[0m in \u001b[0;36mescape_item\u001b[1;34m(val, charset, mapping)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcharset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pymysql\\converters.py\u001b[0m in \u001b[0;36mescape_unicode\u001b[1;34m(value, mapping)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mescape_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;34mu\"'%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_escape_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mescape_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pymysql\\converters.py\u001b[0m in \u001b[0;36m_escape_unicode\u001b[1;34m(value, mapping)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mValue\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \"\"\"\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_escape_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'translate'"
     ]
    }
   ],
   "source": [
    "def add_score(studentID, majorid, score, grade) :\n",
    "    # 쿼리문\n",
    "    sql = '''insert into score\n",
    "             (studentID, majorid, subject_number, score, grade) values (%s, %s, %s, %s, %s)'''\n",
    "\n",
    "    # 접속\n",
    "    conn = get_connection()\n",
    "    # 쿼리실행\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql, (studentID, majorid, subject_number, score, grade))\n",
    "\n",
    "    # 접속해제\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "df = pd.read_csv('../node/data/g.csv')\n",
    "get_connection()\n",
    "for i in df.index :\n",
    "    a = subject[subject['subject_name']==df['교과목명'][i]]\n",
    "    b = a.index.values\n",
    "    b = int(b[0])\n",
    "    add_score(df['class_number'][i],b, float(df['평점'][i]), df['등급'][i])    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = pd.read_csv('../node/data/등급분류완료.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'소속'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '소속'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-230-bf065e90fd14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mclass_number\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'소속'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mclass_number\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'class_number_y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mclass_number\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'departID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__delitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3313\u001b[0m             \u001b[1;31m# there was no match, this call should raise the appropriate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3314\u001b[0m             \u001b[1;31m# exception:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3315\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3317\u001b[0m         \u001b[1;31m# delete from the caches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mdelete\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    983\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mselected\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mitems\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnon\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \"\"\"\n\u001b[1;32m--> 985\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[0mis_deleted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '소속'"
     ]
    }
   ],
   "source": [
    "del class_number['소속']\n",
    "del class_number['class_number_y']\n",
    "del class_number['departID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = pd.merge(final_score, class_number, left_on = 'class_number', right_on = 'class_number_x' ,how= 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_number</th>\n",
       "      <th>grade</th>\n",
       "      <th>Coding</th>\n",
       "      <th>Math</th>\n",
       "      <th>Teamwork</th>\n",
       "      <th>activity</th>\n",
       "      <th>등급</th>\n",
       "      <th>class_number_x</th>\n",
       "      <th>studentID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s1</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s10</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s10</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s100</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>Gold</td>\n",
       "      <td>s100</td>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s1000</td>\n",
       "      <td>3.026316</td>\n",
       "      <td>3.031250</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.026316</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s1000</td>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s1001</td>\n",
       "      <td>3.062500</td>\n",
       "      <td>3.041667</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.062500</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1001</td>\n",
       "      <td>1596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s1002</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1002</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s1003</td>\n",
       "      <td>2.973684</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.973684</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1003</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s1004</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>2.041667</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1004</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s1005</td>\n",
       "      <td>2.529412</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.529412</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1005</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s1006</td>\n",
       "      <td>2.868421</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.868421</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s1006</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>s1007</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1007</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>s1008</td>\n",
       "      <td>2.366667</td>\n",
       "      <td>2.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.366667</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1008</td>\n",
       "      <td>1283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>s1009</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1009</td>\n",
       "      <td>1284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>s101</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s101</td>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>s1010</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>3.307692</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1010</td>\n",
       "      <td>1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>s1011</td>\n",
       "      <td>2.692308</td>\n",
       "      <td>2.636364</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.692308</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1011</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>s1012</td>\n",
       "      <td>3.272727</td>\n",
       "      <td>3.312500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.272727</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s1012</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>s1013</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s1013</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s1014</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1014</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>s1015</td>\n",
       "      <td>3.708333</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.708333</td>\n",
       "      <td>Gold</td>\n",
       "      <td>s1015</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>s1016</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1016</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>s1017</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>1.441176</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1017</td>\n",
       "      <td>1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>s1018</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1018</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>s1019</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1019</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>s102</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>3.775000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s102</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>s1020</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1020</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>s1021</td>\n",
       "      <td>2.789474</td>\n",
       "      <td>2.781250</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.789474</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1021</td>\n",
       "      <td>1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>s1022</td>\n",
       "      <td>3.269231</td>\n",
       "      <td>3.363636</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.269231</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1022</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>s1023</td>\n",
       "      <td>4.055556</td>\n",
       "      <td>3.928571</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.055556</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>s1023</td>\n",
       "      <td>1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>s1024</td>\n",
       "      <td>3.214286</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.214286</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s1024</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>s972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s972</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>s973</td>\n",
       "      <td>3.225000</td>\n",
       "      <td>3.281250</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.225000</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s973</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>s974</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s974</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>s975</td>\n",
       "      <td>3.923077</td>\n",
       "      <td>4.023810</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.923077</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s975</td>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>s976</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s976</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>s977</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s977</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>s978</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.900000</td>\n",
       "      <td>Gold</td>\n",
       "      <td>s978</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>s979</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>2.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s979</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>s98</td>\n",
       "      <td>3.305556</td>\n",
       "      <td>3.294118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.305556</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s98</td>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>s980</td>\n",
       "      <td>3.590909</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.590909</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s980</td>\n",
       "      <td>1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>s981</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s981</td>\n",
       "      <td>1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>s982</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>s982</td>\n",
       "      <td>1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>s983</td>\n",
       "      <td>2.277778</td>\n",
       "      <td>2.343750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>2.277778</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s983</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>s984</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>3.090909</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s984</td>\n",
       "      <td>1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>s985</td>\n",
       "      <td>3.823529</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.823529</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>s985</td>\n",
       "      <td>1268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>s986</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.676471</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s986</td>\n",
       "      <td>1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>s987</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>3.642857</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>Gold</td>\n",
       "      <td>s987</td>\n",
       "      <td>1270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>s988</td>\n",
       "      <td>3.694444</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.694444</td>\n",
       "      <td>Gold</td>\n",
       "      <td>s988</td>\n",
       "      <td>1271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>s989</td>\n",
       "      <td>3.176471</td>\n",
       "      <td>3.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.176471</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s989</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>s99</td>\n",
       "      <td>2.794118</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.794118</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s99</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>s990</td>\n",
       "      <td>3.235294</td>\n",
       "      <td>3.035714</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.235294</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s990</td>\n",
       "      <td>1273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>s991</td>\n",
       "      <td>3.062500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.062500</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s991</td>\n",
       "      <td>1274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>s992</td>\n",
       "      <td>3.131579</td>\n",
       "      <td>3.093750</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.131579</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s992</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>s993</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>2.718750</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s993</td>\n",
       "      <td>1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>s994</td>\n",
       "      <td>3.117647</td>\n",
       "      <td>3.107143</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.117647</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s994</td>\n",
       "      <td>1277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>s995</td>\n",
       "      <td>3.722222</td>\n",
       "      <td>3.785714</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.722222</td>\n",
       "      <td>Gold</td>\n",
       "      <td>s995</td>\n",
       "      <td>1278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>s996</td>\n",
       "      <td>2.558824</td>\n",
       "      <td>2.576923</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.558824</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s996</td>\n",
       "      <td>1279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>s997</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>3.230769</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.133333</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s997</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>s998</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>2.264706</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>Bronze</td>\n",
       "      <td>s998</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>s999</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>Silver</td>\n",
       "      <td>s999</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2609 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class_number     grade    Coding      Math  Teamwork  activity        등급  \\\n",
       "0              s1  3.600000  3.625000  3.500000  0.000000  3.600000    Silver   \n",
       "1             s10  3.500000  3.500000  0.000000  3.500000  3.500000    Bronze   \n",
       "2            s100  3.650000  3.593750  3.666667  4.500000  3.650000      Gold   \n",
       "3           s1000  3.026316  3.031250  3.000000  2.500000  3.026316    Silver   \n",
       "4           s1001  3.062500  3.041667  2.500000  3.000000  3.062500    Bronze   \n",
       "5           s1002  2.416667  2.250000  2.500000  3.333333  2.416667    Bronze   \n",
       "6           s1003  2.973684  3.000000  2.500000  3.000000  2.973684    Bronze   \n",
       "7           s1004  2.300000  2.041667  2.500000  3.500000  2.300000    Bronze   \n",
       "8           s1005  2.529412  2.500000  3.250000  0.000000  2.529412    Bronze   \n",
       "9           s1006  2.868421  3.000000  3.250000  3.000000  2.868421    Silver   \n",
       "10          s1007  3.285714  3.600000  2.000000  3.000000  3.285714    Bronze   \n",
       "11          s1008  2.366667  2.363636  0.000000  3.500000  2.366667    Bronze   \n",
       "12          s1009  2.500000  2.500000  0.000000  2.500000  2.500000    Bronze   \n",
       "13           s101  2.850000  2.777778  3.000000  4.000000  2.850000    Silver   \n",
       "14          s1010  3.111111  3.307692  2.000000  4.500000  3.111111    Bronze   \n",
       "15          s1011  2.692308  2.636364  2.500000  3.500000  2.692308    Bronze   \n",
       "16          s1012  3.272727  3.312500  2.500000  4.500000  3.272727    Silver   \n",
       "17          s1013  3.285714  3.285714  2.875000  4.500000  3.285714    Silver   \n",
       "18          s1014  3.550000  3.666667  0.000000  2.500000  3.550000    Bronze   \n",
       "19          s1015  3.708333  3.600000  4.000000  4.500000  3.708333      Gold   \n",
       "20          s1016  1.916667  1.700000  0.000000  3.000000  1.916667    Bronze   \n",
       "21          s1017  1.450000  1.441176  1.000000  2.500000  1.450000    Bronze   \n",
       "22          s1018  2.357143  2.166667  0.000000  3.500000  2.357143    Bronze   \n",
       "23          s1019  2.700000  2.500000  0.000000  3.500000  2.700000    Bronze   \n",
       "24           s102  3.720000  3.775000  3.500000  3.000000  3.720000    Silver   \n",
       "25          s1020  3.416667  3.566667  2.250000  3.500000  3.416667    Bronze   \n",
       "26          s1021  2.789474  2.781250  2.500000  3.500000  2.789474    Bronze   \n",
       "27          s1022  3.269231  3.363636  2.000000  3.500000  3.269231    Bronze   \n",
       "28          s1023  4.055556  3.928571  4.500000  4.500000  4.055556  Platinum   \n",
       "29          s1024  3.214286  3.300000  2.500000  3.500000  3.214286    Bronze   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "2579         s972  0.000000  0.000000  0.000000  0.000000  0.000000    Bronze   \n",
       "2580         s973  3.225000  3.281250  3.500000  2.500000  3.225000    Silver   \n",
       "2581         s974  3.416667  3.200000  4.500000  0.000000  3.416667    Silver   \n",
       "2582         s975  3.923077  4.023810  4.250000  0.000000  3.923077    Silver   \n",
       "2583         s976  3.500000  3.500000  3.500000  0.000000  3.500000    Silver   \n",
       "2584         s977  3.200000  3.166667  3.500000  0.000000  3.200000    Bronze   \n",
       "2585         s978  3.900000  4.000000  3.500000  3.500000  3.900000      Gold   \n",
       "2586         s979  2.437500  2.214286  0.000000  4.000000  2.437500    Bronze   \n",
       "2587          s98  3.305556  3.294118  0.000000  3.500000  3.305556    Bronze   \n",
       "2588         s980  3.590909  3.375000  4.500000  3.500000  3.590909    Silver   \n",
       "2589         s981  3.666667  3.687500  0.000000  3.500000  3.666667    Bronze   \n",
       "2590         s982  4.000000  3.666667  4.500000  4.500000  4.000000  Platinum   \n",
       "2591         s983  2.277778  2.343750  1.000000  1.750000  2.277778    Bronze   \n",
       "2592         s984  3.125000  3.090909  3.125000  3.500000  3.125000    Silver   \n",
       "2593         s985  3.823529  3.769231  3.833333  4.500000  3.823529  Platinum   \n",
       "2594         s986  2.676471  2.187500  2.000000  4.500000  2.676471    Bronze   \n",
       "2595         s987  3.687500  3.642857  3.500000  4.500000  3.687500      Gold   \n",
       "2596         s988  3.694444  3.750000  3.500000  3.500000  3.694444      Gold   \n",
       "2597         s989  3.176471  3.176471  0.000000  0.000000  3.176471    Bronze   \n",
       "2598          s99  2.794118  2.750000  2.500000  4.000000  2.794118    Bronze   \n",
       "2599         s990  3.235294  3.035714  3.500000  4.500000  3.235294    Silver   \n",
       "2600         s991  3.062500  3.000000  3.500000  3.500000  3.062500    Silver   \n",
       "2601         s992  3.131579  3.093750  3.250000  0.000000  3.131579    Bronze   \n",
       "2602         s993  2.777778  2.718750  2.000000  4.500000  2.777778    Bronze   \n",
       "2603         s994  3.117647  3.107143  3.166667  0.000000  3.117647    Bronze   \n",
       "2604         s995  3.722222  3.785714  3.166667  4.500000  3.722222      Gold   \n",
       "2605         s996  2.558824  2.576923  2.166667  3.500000  2.558824    Bronze   \n",
       "2606         s997  3.133333  3.230769  2.500000  0.000000  3.133333    Bronze   \n",
       "2607         s998  2.357143  2.264706  2.500000  3.000000  2.357143    Bronze   \n",
       "2608         s999  3.250000  3.250000  3.166667  3.500000  3.250000    Silver   \n",
       "\n",
       "     class_number_x  studentID  \n",
       "0                s1        893  \n",
       "1               s10        902  \n",
       "2              s100        952  \n",
       "3             s1000       1595  \n",
       "4             s1001       1596  \n",
       "5             s1002        785  \n",
       "6             s1003        786  \n",
       "7             s1004        787  \n",
       "8             s1005        788  \n",
       "9             s1006        789  \n",
       "10            s1007        380  \n",
       "11            s1008       1283  \n",
       "12            s1009       1284  \n",
       "13             s101        953  \n",
       "14            s1010       1285  \n",
       "15            s1011        381  \n",
       "16            s1012        382  \n",
       "17            s1013       1286  \n",
       "18            s1014        383  \n",
       "19            s1015        384  \n",
       "20            s1016       1287  \n",
       "21            s1017       1288  \n",
       "22            s1018       1289  \n",
       "23            s1019       1290  \n",
       "24             s102         16  \n",
       "25            s1020       1291  \n",
       "26            s1021       1292  \n",
       "27            s1022        385  \n",
       "28            s1023       1293  \n",
       "29            s1024        386  \n",
       "...             ...        ...  \n",
       "2579           s972        378  \n",
       "2580           s973        379  \n",
       "2581           s974        780  \n",
       "2582           s975        781  \n",
       "2583           s976        782  \n",
       "2584           s977        783  \n",
       "2585           s978       1262  \n",
       "2586           s979       1263  \n",
       "2587            s98        951  \n",
       "2588           s980       1264  \n",
       "2589           s981       1265  \n",
       "2590           s982       1266  \n",
       "2591           s983        784  \n",
       "2592           s984       1267  \n",
       "2593           s985       1268  \n",
       "2594           s986       1269  \n",
       "2595           s987       1270  \n",
       "2596           s988       1271  \n",
       "2597           s989       1272  \n",
       "2598            s99         15  \n",
       "2599           s990       1273  \n",
       "2600           s991       1274  \n",
       "2601           s992       1275  \n",
       "2602           s993       1276  \n",
       "2603           s994       1277  \n",
       "2604           s995       1278  \n",
       "2605           s996       1279  \n",
       "2606           s997       1280  \n",
       "2607           s998       1281  \n",
       "2608           s999       1282  \n",
       "\n",
       "[2609 rows x 9 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def add_final(studentID, name, coding, teample, spec, grade, math, final_grade, check_date) :\n",
    "    # 쿼리문\n",
    "    sql = '''insert into final_score\n",
    "             (studentID, name, coding, teample, spec, grade, math, final_grade, check_date) values (%s, %s, %s, %s, %s, %s, %s, %s, %s)'''\n",
    "\n",
    "    # 접속\n",
    "    conn = get_connection()\n",
    "    # 쿼리실행\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql, (studentID, name, coding, teample, spec, grade, math, final_grade, check_date))\n",
    "\n",
    "    # 접속해제\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "for i in final_score.index :\n",
    "    add_final(int(final_score['studentID'][i]) ,final_score['class_number'][i], float(final_score['Coding'][i]), float(final_score['Teamwork'][i]), float(final_score['activity'][i])\n",
    "              , float(final_score['grade'][i])\n",
    "              , float(final_score['Math'][i])\n",
    "              , final_score['등급'][i]\n",
    "              , datetime.date.today())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(datetime.date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_department(univID, name) :\n",
    "    # 쿼리문\n",
    "    sql = '''insert into department\n",
    "             (univID, name) values (%s, %s)'''\n",
    "\n",
    "    # 접속\n",
    "    conn = get_connection()\n",
    "    # 쿼리실행\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql, (univID, name))\n",
    "\n",
    "    # 접속해제\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for i in depart.index :\n",
    "    add_department(int(depart['departID'][i]), depart['소속'][i])\n",
    "    k = k+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knn_final.predict.pkl']"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "knn_final = 'knn_final.predict.pkl'\n",
    "joblib.dump('capstone',knn_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
